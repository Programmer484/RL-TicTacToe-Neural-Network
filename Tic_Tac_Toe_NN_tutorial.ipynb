{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Programmer484/Tic-Tac-Toe-Neural-Network/blob/main/Tic_Tac_Toe_NN_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxRMGC575-3O"
      },
      "source": [
        "**Hey! If you're looking for a fun interactive way to get into machine learning, you're in the right place!** üòÄ\n",
        "\n",
        "Today, we'll be applying reinforcement learning to train an AI that can play tic-tac-toe on various board sizes! For example, 3 in a row on a 3x3 board (regular), 4 in a row on 6x6 board, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMta9EAxC9Qp"
      },
      "source": [
        "### Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First off, let's start off with a sneak peek at what we'll be building throughout this tutorial üëÄ\n",
        "\n",
        "Instructions:\n",
        "\n",
        "1. Run the cell called \"final code\". It contains all the functions that will be used in training and playing.\n",
        "2. Train the neural network\n",
        "3. Play against it!\n"
      ],
      "metadata": {
        "id": "BXKLt350ehye"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7SFVIryEBzY"
      },
      "source": [
        "#### Final code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbCdU5-vDZRE"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "torch.set_printoptions(sci_mode=False, linewidth=120)\n",
        "\n",
        "def position_to_tensor(board, net):\n",
        "    device = \"cuda\" if next(net.parameters()).is_cuda else \"cpu\"\n",
        "    position = torch.Tensor(board.state) * board.turn\n",
        "    position = position.unsqueeze(0).to(device)\n",
        "    return position\n",
        "\n",
        "\"\"\"Network\"\"\"\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, width, height):\n",
        "        super().__init__()\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        # common layers\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        # action policy layers\n",
        "        self.act_conv1 = nn.Conv2d(128, 4, kernel_size=1)\n",
        "        self.act_fc1 = nn.Linear(4*width*height,\n",
        "                         width*height)\n",
        "        # value prediction layers\n",
        "        self.val_conv1 = nn.Conv2d(128, 2, kernel_size=1)\n",
        "        self.val_fc1 = nn.Linear(2*width*height, 64)\n",
        "        self.val_fc2 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, net_input):\n",
        "        # common layers\n",
        "        x = F.relu(self.conv1(net_input))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        # action policy layers\n",
        "        x_act = F.relu(self.act_conv1(x))\n",
        "        x_act = x_act.view(-1, 4*self.width*self.height)\n",
        "        x_act = F.softmax(self.act_fc1(x_act), dim=1)\n",
        "        x_act = x_act.view(-1, self.width, self.height)\n",
        "        # value prediction layers\n",
        "        x_val = F.relu(self.val_conv1(x))\n",
        "        x_val = x_val.view(-1, 2*self.width*self.height)\n",
        "        x_val = F.relu(self.val_fc1(x_val))\n",
        "        x_val = torch.tanh(self.val_fc2(x_val))\n",
        "        return x_act, x_val\n",
        "\n",
        "\"\"\"Board\"\"\"\n",
        "class Board:\n",
        "    def __init__(self, width, height, win_length, turn, state=None, empties=None):\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.win_length = win_length\n",
        "        self.turn = float(turn)\n",
        "        if state == None:\n",
        "            self.state = tuple([0.0 for _ in range (width)] for _ in range(height))\n",
        "            self.empties = [(x, y) for y in range (height) for x in range(width)]\n",
        "        else:\n",
        "            self.state = tuple([x for x in y] for y in state)\n",
        "            self.empties = [e for e in empties]\n",
        "    def __str__(self):\n",
        "        board_state_as_str = \"\"\n",
        "        board_state = [row.copy() for row in self.state]\n",
        "        for row in board_state:\n",
        "            for i, token in enumerate(row):\n",
        "                if token == 1.0:\n",
        "                    row[i] = \"X\"\n",
        "                elif token == -1.0:\n",
        "                    row[i] = \"O\"\n",
        "                elif token == 0.0:\n",
        "                    row[i] = \"_\"\n",
        "            board_state_as_str += str(row) + \"\\n\"\n",
        "        return board_state_as_str\n",
        "    def deepcopy(self):\n",
        "        board = Board(self.width, self.height, self.win_length, self.turn, self.state, self.empties)\n",
        "        return board\n",
        "    def out_of_bounds(self, square, max_x, max_y):\n",
        "        return (square[0] < 0 or square[1] < 0 or square[0] >= max_x or square[1] >= max_y)\n",
        "    def outcome(self, updated_square):\n",
        "        player_num = self.state[updated_square[1]][updated_square[0]]\n",
        "        vectors = []\n",
        "        for x in [-1, 0, 1]:\n",
        "            for y in [-1, 0, 1]:\n",
        "                if x == 0 and y == 0:\n",
        "                    continue\n",
        "                # if a neighbouring square is out of bounds, skip to the next coordinate\n",
        "                if updated_square[0] - 1 < 0 and x == -1:  # past left edge\n",
        "                    continue\n",
        "                if updated_square[0] + 1 > self.width - 1 and x == 1:  # past right edge\n",
        "                    continue\n",
        "                if updated_square[1] - 1 < 0 and y == -1:  # past top edge\n",
        "                    continue\n",
        "                if updated_square[1] + 1 > self.height - 1 and y == 1:  # past bottom edge\n",
        "                    continue\n",
        "                neighbour_x, neighbour_y = updated_square[0] + x, updated_square[1] + y\n",
        "                if self.state[neighbour_y][neighbour_x] == player_num:\n",
        "                    vector = (neighbour_x - updated_square[0], neighbour_y - updated_square[1])\n",
        "                    if vector not in [(v[0]*-1, v[1]*-1) for v in vectors]: # if there is not already a vector in the opposite direction\n",
        "                        vectors.append(vector)\n",
        "        for vector in vectors:\n",
        "            line_length = 1\n",
        "            reversing = False\n",
        "            i = 1\n",
        "            # Keep checking adjacent squares in one direction and increase the row length by 1 whenever the token matches the token just placed\n",
        "            # When an edge, empty space, or opponent token is encountered, count squares in the opposite direction skipping over all the ones we already counted\n",
        "            while i < self.win_length:\n",
        "                if not reversing:\n",
        "                    x = updated_square[0] + i * vector[0]\n",
        "                    y = updated_square[1] + i * vector[1]\n",
        "                    next_square = x, y\n",
        "                else:\n",
        "                    x = updated_square[0] + i * -vector[0]\n",
        "                    y = updated_square[1] + i * -vector[1]\n",
        "                    next_square = x, y\n",
        "\n",
        "                if self.out_of_bounds(next_square, self.width, self.height) \\\n",
        "                or self.state[next_square[1]][next_square[0]] != player_num:\n",
        "                    if not reversing:\n",
        "                        reversing = True\n",
        "                        i = 0\n",
        "                    else:\n",
        "                        break\n",
        "                else:\n",
        "                    line_length += 1\n",
        "                    if line_length >= self.win_length:\n",
        "                        return player_num\n",
        "                i += 1\n",
        "        if len(self.empties) == 0:\n",
        "            return 0.0\n",
        "        return None\n",
        "    def make_move(self, move_coords: tuple):\n",
        "        self.empties.remove(move_coords)\n",
        "        self.state[move_coords[1]][move_coords[0]] = self.turn\n",
        "        self.turn *= -1.0\n",
        "\n",
        "\n",
        "\"\"\"MCTS\"\"\"\n",
        "class Node:\n",
        "    def __init__(self, parent, prob, board, move):\n",
        "        self.parent = parent\n",
        "        self.children = []\n",
        "        self.visit_count = 0\n",
        "        self.total_value = 0\n",
        "        self.value = 0\n",
        "        self.prob = prob\n",
        "        self.board = board\n",
        "        self.move = move\n",
        "\n",
        "    def is_terminal(self):\n",
        "        return self.board.outcome(self.move) != None\n",
        "\n",
        "    def is_leaf(self):\n",
        "        return self.children == []\n",
        "class MCTS:\n",
        "    \"\"\"Search function always evaluates the best move for the 1s player\"\"\"\n",
        "    def __init__(self, board, net):\n",
        "        self.net = net\n",
        "        self.root_node = Node(None, None, board, (-2, -2))\n",
        "        self.c_puct = 1.0\n",
        "        self.tau = 1.0\n",
        "    def uct(self, parent, node):\n",
        "        return self.c_puct * node.prob * (math.sqrt(parent.visit_count)/(1 + node.visit_count))\n",
        "\n",
        "    def select(self, node):\n",
        "        if node.is_leaf():\n",
        "            return node\n",
        "        else:\n",
        "            max_value = -500000\n",
        "            chosen_node = None\n",
        "            for child_node in node.children:\n",
        "                uct_val = self.uct(node, child_node)\n",
        "                q_val = child_node.value * node.board.turn\n",
        "                value = q_val + uct_val\n",
        "                if value > max_value:\n",
        "                    max_value = value\n",
        "                    chosen_node = child_node\n",
        "            return self.select(chosen_node)\n",
        "    def expand_to_backprop(self, node):\n",
        "        position_as_tensor = position_to_tensor(node.board, self.net)\n",
        "        net_output = self.net(position_as_tensor)\n",
        "        legal_moves = node.board.empties\n",
        "        legal_moves_prob_sum = 0.0\n",
        "        for m in legal_moves:\n",
        "            child_prob = net_output[0][0][m[1], m[0]].item()\n",
        "            legal_moves_prob_sum += child_prob\n",
        "        for m in legal_moves:\n",
        "            child_board = node.board.deepcopy()\n",
        "            child_board.make_move(m)\n",
        "            child_prob = net_output[0][0][m[1], m[0]].item()/legal_moves_prob_sum\n",
        "            child_node = Node(node, child_prob, child_board, m)\n",
        "            node.children.append(child_node)\n",
        "        evaluation = net_output[1][0].item() * node.board.turn\n",
        "        self.backpropagate(node, evaluation)\n",
        "\n",
        "    def backpropagate(self, node, evaluation):\n",
        "        node.visit_count += 1\n",
        "        node.total_value += evaluation\n",
        "        node.value = node.total_value / node.visit_count\n",
        "        if node.parent != None:\n",
        "            self.backpropagate(node.parent, evaluation)\n",
        "\n",
        "    def search(self, reps):\n",
        "        torch.set_grad_enabled(False)\n",
        "        for _ in range(reps):\n",
        "            node = self.select(self.root_node)\n",
        "            if node.is_terminal():\n",
        "                self.backpropagate(node, node.board.outcome(node.move))\n",
        "            else:\n",
        "                self.expand_to_backprop(node)\n",
        "        move_probs = []\n",
        "        for child_node in self.root_node.children:\n",
        "            prob = round(child_node.visit_count ** (1/self.tau) / (self.root_node.visit_count ** (1/self.tau)), 3)\n",
        "            move_probs.append((child_node.move, prob))\n",
        "        return move_probs\n",
        "\"\"\"Reinforcement learning\"\"\"\n",
        "class RL:\n",
        "    def __init__(self, net, width, height, win_length):\n",
        "        self.net = net\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.win_length = win_length\n",
        "\n",
        "    def self_play_game(self, mcts_reps):\n",
        "        positions_data = []\n",
        "        move_probs_data = []\n",
        "        values_data = []\n",
        "        game_on = True\n",
        "        board = Board(self.width, self.height, self.win_length, 1)\n",
        "        while game_on:\n",
        "            position_as_tensor = position_to_tensor(board, self.net)\n",
        "            positions_data.append(position_as_tensor)\n",
        "            values_data.append(torch.Tensor([board.turn]))\n",
        "            mcts_searcher = MCTS(board, self.net)\n",
        "            mcts_move_probs = mcts_searcher.search(mcts_reps)\n",
        "            move_probs_matrix = [[0.0] * self.width for y in range(self.height)]  # for the network\n",
        "            moves = [] # for making a move\n",
        "            move_probs = [] # for making a move\n",
        "            for move, prob in mcts_move_probs:\n",
        "                move_probs_matrix[move[1]][move[0]] = prob\n",
        "                moves.append(move)\n",
        "                move_probs.append(prob)\n",
        "            move_probs_matrix = torch.Tensor(move_probs_matrix)\n",
        "            move_probs_data.append(move_probs_matrix)\n",
        "            selected_idx = np.random.multinomial(1, move_probs)\n",
        "            chosen_move = moves[np.where(selected_idx==1)[0][0]]\n",
        "            board.make_move(chosen_move)\n",
        "            value = board.outcome(chosen_move)\n",
        "            if value != None:\n",
        "                for i in range(len(positions_data)):\n",
        "                    values_data[i] *= value\n",
        "                return (positions_data, move_probs_data, values_data)\n",
        "\"\"\"Dataloader\"\"\"\n",
        "class GomokuDataset(Dataset):\n",
        "    def __init__(self, games):\n",
        "        super().__init__()\n",
        "        self.games = games\n",
        "    def __len__(self):\n",
        "        return len(self.games[0])\n",
        "    def __getitem__(self, index):\n",
        "        return self.games[0][index], self.games[1][index], self.games[2][index]\n",
        "\n",
        "\"\"\"Play games\"\"\"\n",
        "def net_choose_move(board, net):\n",
        "    torch.set_grad_enabled(False)\n",
        "    position_as_tensor = position_to_tensor(board, net)\n",
        "    move_probs = net(position_as_tensor)[0][0]\n",
        "    vals = []\n",
        "    total_val = 0\n",
        "    for square in board.empties:\n",
        "        total_val += (move_probs[square[1], square[0]]) ** 1\n",
        "    for square in board.empties:\n",
        "        val = move_probs[square[1], square[0]].to(\"cpu\")\n",
        "        vals.append(math.floor(val ** 1/total_val * 5000)/5000)\n",
        "    selected_idx = np.random.multinomial(1, vals)\n",
        "    chosen_move = board.empties[np.where(selected_idx==1)[0][0]]\n",
        "    return chosen_move\n",
        "\n",
        "\n",
        "def mcts_net_vs_human(board, mcts_reps, net):\n",
        "    game_on = True\n",
        "    while game_on:\n",
        "        if board.turn == 1:\n",
        "            print(f\"======= X player's turn to move =======\")\n",
        "            if mcts_reps > 0:\n",
        "                mcts_searcher = MCTS(board, net)\n",
        "                mcts_move_probs = mcts_searcher.search(mcts_reps)\n",
        "                chosen_move = max(mcts_move_probs, key=lambda x: x[1])[0]\n",
        "            else:\n",
        "                chosen_move = net_choose_move(board, net)\n",
        "                position_as_tensor = position_to_tensor(board, net)\n",
        "                net_output = net(position_as_tensor)\n",
        "                print(f\"Move probabilities: \\n{net_output[0][0]}\\n\")\n",
        "                print(f\"Outcome prediction: \\n{net_output[1][0]}\\n\")\n",
        "            board.make_move(chosen_move)\n",
        "        else:\n",
        "            print(f\"======= O player's turn to move =======\")\n",
        "            try:\n",
        "                x = input(\"x: \")\n",
        "                y = input(\"y: \")\n",
        "                chosen_move = (int(x), int(y))\n",
        "                board.make_move(chosen_move)\n",
        "            except Exception:\n",
        "                print(\"Invalid move, please try again\")\n",
        "                continue\n",
        "\n",
        "        print(\"Board:\")\n",
        "        print(board)\n",
        "        value = board.outcome(chosen_move)\n",
        "        if value != None:\n",
        "            break\n",
        "\n",
        "\n",
        "def net_vs_net(start_board, net1, net2, games):\n",
        "    win_count = [0, 0]\n",
        "    for game in range(games):\n",
        "        if game % 2 == 0:\n",
        "            nets = (net1, net2)\n",
        "            first_net_idx = 0\n",
        "            second_net_idx = 1\n",
        "        else:\n",
        "            nets = (net2, net1)\n",
        "            first_net_idx = 1\n",
        "            second_net_idx = 0\n",
        "        board = start_board.deepcopy()\n",
        "        game_on = True\n",
        "        net_outputs = []\n",
        "        while game_on:\n",
        "            if board.turn == 1.0:\n",
        "                net = nets[0]\n",
        "            else:\n",
        "                net = nets[1]\n",
        "\n",
        "            chosen_move = net_choose_move(board, net)\n",
        "\n",
        "            # mcts_searcher = MCTS(board, net)\n",
        "            # mcts_move_probs = mcts_searcher.search(200)\n",
        "            # chosen_move = max(mcts_move_probs, key=lambda x: x[1])[0]\n",
        "\n",
        "            # move_probs_matrix = [[0.0] * board.width for y in range(board.height)]  # for the network\n",
        "            # for move, prob in mcts_move_probs:\n",
        "            #     move_probs_matrix[move[1]][move[0]] = prob\n",
        "            # move_probs_matrix = torch.Tensor(move_probs_matrix)\n",
        "            # position_as_tensor = position_to_tensor(board, net)\n",
        "            # net_output = net(position_as_tensor)\n",
        "            # net_outputs.extend((move_probs_matrix, net_output[1][0], chosen_move))\n",
        "\n",
        "            board.make_move(chosen_move)\n",
        "            value = board.outcome(chosen_move)\n",
        "\n",
        "            if value != None:\n",
        "                if value == 1.0:\n",
        "                    win_count[first_net_idx] += 1\n",
        "                elif value == -1.0:\n",
        "                    win_count[second_net_idx] += 1\n",
        "                game_on = False\n",
        "    return win_count\n",
        "\n",
        "\"\"\"Train\"\"\"\n",
        "def train(main_net, opponent_net, learner, generations, games_per_generation, training_epochs):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    main_net = main_net.to(device)\n",
        "    opponent_net = opponent_net.to(device)\n",
        "    for generation in range(1, generations):\n",
        "        # game generation\n",
        "        all_positions = []\n",
        "        all_move_probs = []\n",
        "        all_values = []\n",
        "        st = time.perf_counter()\n",
        "        for game in range(games_per_generation):\n",
        "            positions, move_probs, values = learner.self_play_game(200)\n",
        "            all_positions += positions\n",
        "            all_move_probs += move_probs\n",
        "            all_values += values\n",
        "        et = time.perf_counter()\n",
        "        print(f\"===== Game generation time in seconds: {et-st} ======\")\n",
        "        all_games = (all_positions, all_move_probs, all_values)\n",
        "        # data preparation\n",
        "        train_data = GomokuDataset(all_games)\n",
        "        train_data_loader = DataLoader(train_data, batch_size=32, shuffle=True, drop_last=False)\n",
        "        # training\n",
        "        torch.set_grad_enabled(True)\n",
        "        policy_loss_metric = nn.BCELoss()\n",
        "        value_loss_metric = nn.MSELoss()\n",
        "        optimizer = torch.optim.Adam(main_net.parameters(), lr=0.003, weight_decay=1e-4)\n",
        "        for epoch in range(training_epochs):\n",
        "            running_loss = 0\n",
        "            for position, move_probs, value in train_data_loader:\n",
        "                position, move_probs, value = position.to(device), move_probs.to(device), value.to(device)\n",
        "                output = main_net(position)\n",
        "                policy_loss = policy_loss_metric(output[0], move_probs)\n",
        "                value_loss = value_loss_metric(output[1], value)\n",
        "                loss = policy_loss + value_loss\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "            print(f\"Training loss: {running_loss/len(train_data_loader)}\")\n",
        "        # evaluating model\n",
        "        win_counts = net_vs_net(Board(3, 3, 3, 1), main_net, opponent_net, 1000)\n",
        "        print(\"\")\n",
        "        print(f\"main_net wins: {win_counts[0]}\")\n",
        "        print(f\"main_net losses: {win_counts[1]}\")\n",
        "        print(f\"main_net draws: {1000 - win_counts[0] - win_counts[1]}\")\n",
        "        if win_counts[0] - win_counts[1] > 150:\n",
        "            torch.save(main_net.state_dict(), f\"model_{generation}.pt\")\n",
        "            opponent_net.load_state_dict(torch.load(f\"model_{generation}.pt\"))\n",
        "            print(f\"Saved model {generation}\")\n",
        "            print(f\"Updated opponent_net to copy of main_net\")\n",
        "\n",
        "\n",
        "\n",
        "main_net = Net(3, 3)\n",
        "# main_net.load_state_dict(torch.load(\"model.pt\"))\n",
        "opponent_net = Net(3, 3)\n",
        "learner = RL(main_net, 3, 3, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train the network"
      ],
      "metadata": {
        "id": "GydgEzvkXJNC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feel free to experiment with the last three parameters which are: # network generations, # games generated per generation, and # training epochs per generation"
      ],
      "metadata": {
        "id": "tKobx33-kA4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(main_net, opponent_net, learner, 5, 80, 15)"
      ],
      "metadata": {
        "id": "evoDTGWfXNAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Play against the network!"
      ],
      "metadata": {
        "id": "id_EIuMwfKCM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The outputs will be:\n",
        "\n",
        "1. The board\n",
        "2. The network's move policy as a grid\n",
        "3. The network's prediction of who will win\n",
        "  * &nbsp;1.00 = 100% confident Xs win\n",
        "  * -1.00 = 100% confident Os win\n",
        "  * &nbsp;0.00 = 100% confident of a tie\n",
        "\n",
        "\n",
        "* The top left square is (0, 0)\n",
        "* Input the x-coordinate of your desired square, press enter, then input the y-coordinate."
      ],
      "metadata": {
        "id": "CzKz1WPkkVrS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DR19OvvhWQ_U"
      },
      "outputs": [],
      "source": [
        "board = Board(3, 3, 3, 1)  # -1 means you go first, 1 means network goes first\n",
        "mcts_net_vs_human(board, 0, main_net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_IUiEeBsvS-"
      },
      "source": [
        "### Intro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMTORr-qxZp_"
      },
      "source": [
        "<a name=\"intro\"></a>\n",
        "Well, wasn't that fun!\n",
        "\n",
        "I know you're excited to begin coding, but make sure you have a rough understanding of **Python** and **neural networks** before we begin. If not, there are some resources below.\n",
        "\n",
        "Just make sure you DON'T GO DOWN A YOUTUBE/WEB SURFING RABBIT HOLE!! Set yourself a loud timer ‚Äî at least as loud as an atomic bomb going off next to you ‚Äî for however long you intend to learn/research. Then get back here as soon as it goes off!\n",
        "\n",
        "1. Python\n",
        "  * If you already have programming knowledge: just look up keywords as you go. Personally I recommend w3schools.\n",
        "  * If you have never coded before: check out one of the two resources here. The key is to learning is to DO THE EXERCISES!!\n",
        "    * https://nostarch.com/download/Python_for_Kids_Solutions__Briggs.pdf\n",
        "      * It doesn't matter whether you are a kid or an adult. The explanations are very intuitive.\n",
        "\n",
        "    * https://automatetheboringstuff.com/#toc\n",
        "      * Go up to chapter 6\n",
        "\n",
        "2. How a neural network works\n",
        "  * [Videos + Interactive Demo](https://www.3blue1brown.com/lessons/neural-networks)\n",
        "    * Go up to chapter 4\n",
        "    * ~20 min / chapter\n",
        "  * [Article](https://ryan-leong.medium.com/the-basics-of-neural-networks-for-chess-nerds-and-anyone-interested-in-ai-e76e03124867)\n",
        "    * Refresher for if you've already learned about NNs in the past\n",
        "    * ~15 min\n",
        "  * I recommend understanding neural networks before we start building, but if you are reaaaaally so excited to start coding, then\n",
        "    * **think of a neural network as a toddler who learns as they are repeatedly shown what to do (output) in a given situation (input)**. For example, be quiet when the parents are sleeping, but be loud when only their siblings are sleeping. When they do the wrong thing, we ~give them a whack on the butt~ show them how they can adjust their actions to get better.\n",
        "    * If you want something closer to what an actual neural network is, then think of the network as a very complex mathematical function with many constants and terms. Whenever we train the network, we are making adjustments to these constants so the function better maps our input to our desired output.\n",
        "\n",
        "\n",
        "\n",
        "**IMPORTANT!** Whenever you see this:\n",
        "\n",
        "üõë + üß†\n",
        "\n",
        "It means you should pause and think about the prompt for 1+ minutes. Take as long as you need.\n",
        "\n",
        "In fact, right now I want you to grab a piece of paper, or open a plaintext file so you can write/type your thoughts there as you think.\n",
        "\n",
        "This is **where the learning happens!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dor5jatsDlw"
      },
      "source": [
        "### The plan"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basically what we're going to do, is show our neural network a bunch of positions and teach it what the best move is in each position.\n",
        "\n",
        "As it learns what the best move in various positions are, the network will eventually learn to recognize patterns, like the fact that it should always take an opportunity to place a token that forms 3 in a row, leading to victory.\n",
        "\n",
        "Any questions?\n",
        "\n",
        "üõë + üß†\n",
        "\n",
        "Hopefully most of your questions will be answered throughout the tutorial, but the most pressing ones would be:\n",
        "\n",
        "1. Where are we going to get these positions and best moves from?\n",
        "\n",
        "Let's think about this one together. Paper/text file time!\n",
        "\n",
        "üõë + üß†\n",
        "\n",
        "The first option would be to use a database of tic-tac-toe games that also includes the best move for each position in each game. Using this approach would be considered supervised learning.\n",
        "\n",
        "We might be able to find a database for typical tic-tac-toe on a 3x3 board, but if we want to train our network to on different board sizes and win_lengths, we're going to have to **generate our own database**.\n",
        "\n",
        "To accomplish this, first we generate games by getting an AI or algorithm to play lots of games against itself. Then, we'll need to run an **algorithm** on each position in each game **which returns the best move**. The data generated should be formatted in the same way as database we'd use for supervised learning, with several pairings of a positions + the best move.\n",
        "\n",
        "Of course you might be thinking, but what if we were trying to use reinforcement learning on a game that we _don't_ have a good known algorithm for finding the best move? Don't worry, there's an algorithm works for **any game**. WhoaaaaaüòØ\n",
        "\n",
        "#### Recap\n",
        "\n",
        "In short, we're going to repeat the following two steps until network reaches its desired strength:\n",
        "  - Generate games through self-play\n",
        "  - Train the network with these generated games\n",
        "\n",
        "Let's beginÔºÅüèÅ"
      ],
      "metadata": {
        "id": "dvFG2Ov8qLdn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVMG-x2DWlTz"
      },
      "source": [
        "### Generating games through self-play"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfupaCdvszqZ"
      },
      "source": [
        "Try writing down all the steps/parts of how we can generate a database of positions and their best moves when we don't already have one.\n",
        "\n",
        "No peeking at the previous cell!üôà\n",
        "\n",
        "üõë + üß†\n",
        "\n",
        "Done? Hopefully you included at least two of these three steps:\n",
        "1. The game engine, which allows us to track the tokens on the board and check when one player has won\n",
        "2. An AI or algorithm to choose moves for both sides\n",
        "3. An algorithm which returns the best move for each position\n",
        "\n",
        "But first, let's build the game engine!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3DFL1tkVeec"
      },
      "source": [
        "#### Game engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apqRz2a7Wh25"
      },
      "source": [
        "The game engine is actually a great thing to try coding yourself :)\n",
        "\n",
        "Two things I STRONGLY recommend for all coding exercises going forwards:\n",
        "\n",
        "1. Copy and paste exercise code into a code editor like replit or VS code\n",
        "  - Far **superior debugging abilities**. Search up \"replit debugger\" if you've never used breakpoints in replit\n",
        "  - You won't have to search for code cells in Google colab if you don't finish the tutorial in one session.\n",
        "2. Turn off code generation/suggestion\n",
        "  - I think it takes away a lot of the thinking that's so crucial to learning something new.\n",
        "\n",
        "I've added some checkpoints to help guide you below. The internet is your friend when you get stuck.\n",
        "\n",
        "Well, a treacherous friend because sometimes it will betray you by leading you down a useless rabbit hole. Just stay intentional üòâ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYWDdeYIgq_c"
      },
      "source": [
        "Stage 1: Create a class that keeps track of the game state and allows you to place tokens with a move method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZ_LtLlaZJHz"
      },
      "outputs": [],
      "source": [
        "# Exercise\n",
        "class Board:\n",
        "    def __init__(self, state):\n",
        "        self.state = state\n",
        "\n",
        "    def make_move(self, move):\n",
        "        pass\n",
        "\n",
        "    def outcome(self):  # This function is for later\n",
        "        pass\n",
        "\n",
        "# Let's use 0s for empty spaces, and -1s and 1s to represent the two players.\n",
        "# Using numbers instead of strings will be helpful when we later need to feed our board position to a neural network\n",
        "start_state = [[-1,  0,  0],\n",
        "               [ 0,  0,  0],\n",
        "               [ 0,  0,  1]]\n",
        "\n",
        "board = Board(start_state)\n",
        "\n",
        "board.make_move((1, 1))\n",
        "print(board.state)\n",
        "\n",
        "board.make_move((1, 1))  # This should throw an error since the space is already occupied\n",
        "\n",
        "\n",
        "# Expected outcomes\n",
        "after_move1 = [[-1,  0,  0],\n",
        "               [ 0,  1,  0],\n",
        "               [ 0,  0,  1]]\n",
        "after_move2 = \"Space already occupied, please don't sit on other people.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFbvbRZ9gn7u"
      },
      "source": [
        "Stage 2: Alternate between placing 1s and -1s depending on whose turn it is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSu9Pa_iWgkh"
      },
      "outputs": [],
      "source": [
        "# Exercise\n",
        "# Replace this line with your Board class from the previous cell\n",
        "\n",
        "start_state = [[1, -1,  1],\n",
        "               [0,  0,  0],\n",
        "               [0,  0, -1]]\n",
        "\n",
        "board = Board(start_state)\n",
        "\n",
        "board.make_move((0, 0))\n",
        "print(board.state)\n",
        "\n",
        "board.make_move((2, 2))\n",
        "print(board.state)\n",
        "\n",
        "board.make_move((1, 1))\n",
        "print(board.state)\n",
        "\n",
        "\n",
        "# Expected outcomes\n",
        "after_move1 = [[1,  0,  0],\n",
        "               [0,  0,  0],\n",
        "               [0,  0,  0]]\n",
        "\n",
        "after_move2 = [[1,  0,  0],\n",
        "               [0,  0,  0],\n",
        "               [0,  0, -1]]\n",
        "\n",
        "after_move3 = [[1,  0,  1],\n",
        "               [0,  0,  0],\n",
        "               [0,  0, -1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck--APcTgP7Q"
      },
      "source": [
        "Stage 3: Check if the game has ended and return the outcome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgLEgx3Yavjc"
      },
      "outputs": [],
      "source": [
        "# Exercise\n",
        "# Replace this line with your Board class from the previous cell\n",
        "\n",
        "start_state1 = [[ 1,  0, -1],\n",
        "                [ 0,  1, -1],\n",
        "                [ 0,  0,  1]]\n",
        "\n",
        "start_state2 = [[-1,  0,  1],\n",
        "                [-1,  1,  0],\n",
        "                [-1,  0,  0]]\n",
        "\n",
        "start_state3 = [[ 1,  1, -1],\n",
        "                [-1, -1,  1],\n",
        "                [ 1, -1,  1]]\n",
        "\n",
        "start_state4 = [[ 0,  0,  0],\n",
        "                [-1,  1,  1],\n",
        "                [ 0, -1,  0]]\n",
        "\n",
        "board1 = Board(start_state1)\n",
        "board1.outcome()  # should return  1 for  1s player wins\n",
        "\n",
        "board2 = Board(start_state2)\n",
        "board2.outcome()  # should return -1 for -1s player wins\n",
        "\n",
        "board3 = Board(start_state3)\n",
        "board3.outcome()  # should return  0 for draw\n",
        "\n",
        "board4 = Board(start_state4)\n",
        "board4.outcome()  # should return None since the game is not over"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFPDcOc_pQeH"
      },
      "source": [
        "Congrats! You've finished coding the game engine!\n",
        "\n",
        "If you want, you can use your own Board class code going forwards, but I've made a few additional changes to the Board class after actually using it with the rest of tic-tac-toe code.\n",
        "\n",
        "The main changes are an optimized deepcopy function and outcome check function for much faster computation.\n",
        "\n",
        "I'd strongly suggest using the following code going forward just to avoid future bugs/compatability issues with the rest of the tutorial, but remember that you've already done the learning by coding a version of the Board class yourself :)\n",
        "\n",
        "Make sure to paste this at the top of your code editor so you have access to the Board class for the rest of the tutorial! Or run the cell if you are using Google colab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Final Board code"
      ],
      "metadata": {
        "id": "KI1B2gzChF-w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Y4Mvi9AgHg6"
      },
      "outputs": [],
      "source": [
        "# Solution\n",
        "class Board:\n",
        "    def __init__(self, width, height, win_length, turn, state=None, empties=None):\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.win_length = win_length\n",
        "        self.turn = float(turn)\n",
        "        if state == None:\n",
        "            self.state = tuple([0.0 for _ in range (width)] for _ in range(height))\n",
        "            self.empties = [(x, y) for y in range (height) for x in range(width)]\n",
        "        else:\n",
        "            self.state = tuple([x for x in y] for y in state)\n",
        "            self.empties = [e for e in empties]\n",
        "    def __str__(self):\n",
        "        board_state_as_str = \"\"\n",
        "        board_state = [row.copy() for row in self.state]\n",
        "        for row in board_state:\n",
        "            for i, token in enumerate(row):\n",
        "                if token == 1.0:\n",
        "                    row[i] = \"X\"\n",
        "                elif token == -1.0:\n",
        "                    row[i] = \"O\"\n",
        "                elif token == 0.0:\n",
        "                    row[i] = \"_\"\n",
        "            board_state_as_str += str(row) + \"\\n\"\n",
        "        return board_state_as_str\n",
        "    def deepcopy(self):\n",
        "        board = Board(self.width, self.height, self.win_length, self.turn, self.state, self.empties)\n",
        "        return board\n",
        "    def out_of_bounds(self, square, max_x, max_y):\n",
        "        return (square[0] < 0 or square[1] < 0 or square[0] >= max_x or square[1] >= max_y)\n",
        "    def outcome(self, updated_square):\n",
        "        player_num = self.state[updated_square[1]][updated_square[0]]\n",
        "        vectors = []\n",
        "        for x in [-1, 0, 1]:\n",
        "            for y in [-1, 0, 1]:\n",
        "                if x == 0 and y == 0:\n",
        "                    continue\n",
        "                # if a neighbouring square is out of bounds, skip to the next coordinate\n",
        "                if updated_square[0] - 1 < 0 and x == -1:  # past left edge\n",
        "                    continue\n",
        "                if updated_square[0] + 1 > self.width - 1 and x == 1:  # past right edge\n",
        "                    continue\n",
        "                if updated_square[1] - 1 < 0 and y == -1:  # past top edge\n",
        "                    continue\n",
        "                if updated_square[1] + 1 > self.height - 1 and y == 1:  # past bottom edge\n",
        "                    continue\n",
        "                neighbour_x, neighbour_y = updated_square[0] + x, updated_square[1] + y\n",
        "                if self.state[neighbour_y][neighbour_x] == player_num:\n",
        "                    vector = (neighbour_x - updated_square[0], neighbour_y - updated_square[1])\n",
        "                    if vector not in [(v[0]*-1, v[1]*-1) for v in vectors]: # if there is not already a vector in the opposite direction\n",
        "                        vectors.append(vector)\n",
        "        for vector in vectors:\n",
        "            line_length = 1\n",
        "            reversing = False\n",
        "            i = 1\n",
        "            # Keep checking adjacent squares in one direction and increase the row length by 1 whenever the token matches the token just placed\n",
        "            # When an edge, empty space, or opponent token is encountered, count squares in the opposite direction skipping over all the ones we already counted\n",
        "            while i < self.win_length:\n",
        "                if not reversing:\n",
        "                    x = updated_square[0] + i * vector[0]\n",
        "                    y = updated_square[1] + i * vector[1]\n",
        "                    next_square = x, y\n",
        "                else:\n",
        "                    x = updated_square[0] + i * -vector[0]\n",
        "                    y = updated_square[1] + i * -vector[1]\n",
        "                    next_square = x, y\n",
        "\n",
        "                if self.out_of_bounds(next_square, self.width, self.height) \\\n",
        "                or self.state[next_square[1]][next_square[0]] != player_num:\n",
        "                    if not reversing:\n",
        "                        reversing = True\n",
        "                        i = 0\n",
        "                    else:\n",
        "                        break\n",
        "                else:\n",
        "                    line_length += 1\n",
        "                    if line_length >= self.win_length:\n",
        "                        return player_num\n",
        "                i += 1\n",
        "        if len(self.empties) == 0:\n",
        "            return 0.0\n",
        "        return None\n",
        "    def make_move(self, move_coords: tuple):\n",
        "        self.empties.remove(move_coords)\n",
        "        self.state[move_coords[1]][move_coords[0]] = self.turn\n",
        "        self.turn *= -1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwjUrYJFVque"
      },
      "source": [
        "#### Move chooser"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When it comes to choosing moves, the question we have to ask ourselves is, what types of positions do we want our network to be trained on?\n",
        "\n",
        "The more realistic ones of course. That means totally random moves would result in a lot of highly unlikely positions. Even if our best move algorithm always returns the best move in any position, our network won't be able to learn as much when there's a bunch of random tokens in positions where they'd never be in a real game.\n",
        "\n",
        "So we need at least a semi intelligent algorithm or AI choosing the moves.\n",
        "\n",
        "Hey, here's a thought. What if we just use the move recommended by the best move algorithm, since we're going to run it anyways? Yes let's try that!"
      ],
      "metadata": {
        "id": "f76NkIFEDvj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Best move algorithm"
      ],
      "metadata": {
        "id": "QMAEEru4Oaf-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So earlier I mentioned an AMAZING algorithm that can find the best move in any position for any game. Let's see if you can find it with the help of your friend the internet.\n",
        "\n",
        "Just **set a 15 min timer** so you don't get sucked into the black hole of dog/cat pictures or whatever you fancy. Feel free to come back earlier if you think you found something :)\n",
        "\n",
        "üõë + üß†\n",
        "\n",
        "If you thought the existence of such an amazing algorithm was kinda\n",
        "&nbsp;* sus *, you would make a good crewmate in Among Us ‡∂û.\n",
        "\n",
        "Ahh, but I didn't lie. You see, this algorithm does find the best move... given enough _time_. I am speaking of the mighty Monte Carlo Tree Search (MCTS)! üá≤üá® üå≤ üîé\n",
        "\n",
        "Okay jokes aside, MCTS still makes a good domain independent (doesn't matter which game) algorithm for finding good moves. Even if it can't find the best moves on larger boards or in more complex games, it will still act as a good guide.\n",
        "\n",
        "So let's learn how to implement MCTS!"
      ],
      "metadata": {
        "id": "qFpKriFgOetx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MCTS"
      ],
      "metadata": {
        "id": "zB1lnb4oU4PJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'd like to do this like we built the game engine, but this time with more guidance from me.\n",
        "\n",
        "One major component of MCTS is about something known as random *playouts*. Keep in mind we'll start with **a very simplified version of MCTS** and introduce elements as we go, but I'll still call it MCTS.\n",
        "\n",
        "Imagine there is a chess position where White has one move that captures Black's queen for free, and the rest of their moves don't. What MCTS does with random playouts is: for every single move White has in that position, it simulates a bunch of random continuations from that move until the game is over. Given enough simulations, we should find that the move where White captured their opponent's queen leads to an overall higher win rate compared to the moves where it didn't.\n",
        "\n",
        "Let's try coding that for tic-tac-toe.\n",
        "\n",
        "Make sure to run this ```grid_print``` function. We'll be using it in the rest of our MCTS exercises."
      ],
      "metadata": {
        "id": "eZmhIK0qU5mD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grid_print(grid, space=0, decimals=0, title=\"\"):\n",
        "    print(title)\n",
        "    if grid != None:\n",
        "      for row in grid:\n",
        "          print(\"[\", end=\"\")\n",
        "          for col in row:\n",
        "              print(\" \", end=\"\")\n",
        "              exec(\"\"\"print(\"{:%s.%sf},\".format(col), end=\" \")\"\"\" % (space, decimals))\n",
        "          print(\"]\")\n",
        "      print()\n",
        "    else:\n",
        "      print(\"No output\\n\")"
      ],
      "metadata": {
        "id": "pRPJWmaElspW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stage 1: Evaluating positions using random playouts\n",
        "\n",
        "What we want our function to return is a score for each possible move. Ideally we want to have a score of -1 reflect 100% confidence in a win for the -1s player, and 1 reflect 100% confidence in a win for the 1s player.\n",
        "\n",
        "I have given 3 inputs along with their expected outputs. Good luck!"
      ],
      "metadata": {
        "id": "0PfcjHhPMcDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise\n",
        "class MCTS:\n",
        "    def __init__(self, board):\n",
        "        self.board = board\n",
        "\n",
        "    def search(self):\n",
        "        for move in self.board.empties:\n",
        "            pass  # return output as a 2D list\n",
        "\n",
        "# Test cases\n",
        "board1 = Board(3, 3, 3, 1)\n",
        "board1.make_move((0, 0))\n",
        "board1.make_move((1, 1))\n",
        "board1.make_move((0, 1))\n",
        "board1.make_move((0, 2))\n",
        "\n",
        "board2 = Board(3, 3, 3, 1)\n",
        "board2.make_move((0, 0))\n",
        "\n",
        "board3 = Board(3, 3, 3, 1)\n",
        "board3.make_move((0, 0))\n",
        "board3.make_move((1, 1))\n",
        "board3.make_move((2, 2))\n",
        "\n",
        "# Your final scores should roughly resemble the scores in the grids below.\n",
        "grid_print(board1.state, 2, 0, \"Board 1\")\n",
        "mcts_searcher1 = MCTS(board1)\n",
        "grid_print(mcts_searcher1.search(), 5, 2, \"Value grid\")\n",
        "# [[0.00, -0.17,  0.17],\n",
        "#  [0.00,  0.00, -0.83],\n",
        "#  [0.00, -0.33, -0.50]]\n",
        "\n",
        "grid_print(board2.state, 2, 0, \"Board 2\")\n",
        "mcts_searcher2 = MCTS(board2)\n",
        "grid_print(mcts_searcher2.search(), 5, 2, \"Value grid\")\n",
        "# [[0.00, 0.45, 0.29],\n",
        "#  [0.45, 0.12, 0.45],\n",
        "#  [0.29, 0.45, 0.29]]\n",
        "\n",
        "grid_print(board3.state, 2, 0, \"Board 3\")\n",
        "mcts_searcher3 = MCTS(board3)\n",
        "grid_print(mcts_searcher3.search(), 5, 2, \"Value grid\")\n",
        "# [[ 0.00, -0.10, -0.17],\n",
        "#  [-0.10,  0.00, -0.10],\n",
        "#  [-0.17, -0.10,  0.00]]"
      ],
      "metadata": {
        "id": "voGzucFM_KSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great work!\n",
        "\n",
        "Short summary of my solution:\n",
        "1. For each potential move, we first check if it immediately ends the game, and return the corresponding value (-1 for a -1s player win, 0 for a draw, and 1 for a 1s player win) if it does. Otherwise, we move on to simulating games to get an estimate for how good the move is.\n",
        "2. In the ```simulate``` function, we play a set number of random games and take the average outcome of all the random games played to give us our final expected outcome.\n",
        "3. The ```play_random_game``` function keeps making random moves for each side until the game ends. It returns a value of -1 for a -1s player win, 0 for a draw, and 1 for a 1s player win."
      ],
      "metadata": {
        "id": "7OTbQJtXLAJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution\n",
        "import torch\n",
        "import random\n",
        "\n",
        "class MCTS:\n",
        "    def __init__(self, board):\n",
        "        self.board = board\n",
        "\n",
        "    def simulate(self, board, reps):\n",
        "        total_value = 0\n",
        "        for _ in range (reps):\n",
        "            total_value += self.play_random_game(board.deepcopy())\n",
        "        return total_value / reps\n",
        "\n",
        "    def play_random_game(self, board):\n",
        "        game_on = True\n",
        "        while game_on:\n",
        "            move = random.choice(board.empties)\n",
        "            board.make_move(move)\n",
        "            value = board.outcome(move)\n",
        "            if value != None:\n",
        "                return value\n",
        "\n",
        "    def search(self):\n",
        "        move_probability_grid = [[0.0 for x in range(3)] for y in range(3)]\n",
        "        for move in self.board.empties:\n",
        "            new_board = self.board.deepcopy()\n",
        "            new_board.make_move(move)\n",
        "            if new_board.outcome(move) != None:\n",
        "                value = new_board.outcome(move)\n",
        "            else:\n",
        "                value = self.simulate(new_board, 5000)\n",
        "            move_probability_grid[move[1]][move[0]] = value\n",
        "        return move_probability_grid\n",
        "\n",
        "\n",
        "# Test cases\n",
        "board1 = Board(3, 3, 3, 1)\n",
        "board1.make_move((0, 0))\n",
        "board1.make_move((1, 1))\n",
        "board1.make_move((0, 1))\n",
        "board1.make_move((0, 2))\n",
        "\n",
        "board2 = Board(3, 3, 3, 1)\n",
        "board2.make_move((0, 0))\n",
        "\n",
        "board3 = Board(3, 3, 3, 1)\n",
        "board3.make_move((0, 0))\n",
        "board3.make_move((1, 1))\n",
        "board3.make_move((2, 2))\n",
        "\n",
        "# Your final scores should roughly resemble the scores in the grids below.\n",
        "grid_print(board1.state, 2, 0, \"Board 1\")\n",
        "mcts_searcher1 = MCTS(board1)\n",
        "grid_print(mcts_searcher1.search(), 5, 2, \"Value grid\")\n",
        "# [[0.00, -0.17,  0.17],\n",
        "#  [0.00,  0.00, -0.83],\n",
        "#  [0.00, -0.33, -0.50]]\n",
        "\n",
        "grid_print(board2.state, 2, 0, \"Board 2\")\n",
        "mcts_searcher2 = MCTS(board2)\n",
        "grid_print(mcts_searcher2.search(), 5, 2, \"Value grid\")\n",
        "# [[0.00, 0.45, 0.29],\n",
        "#  [0.45, 0.12, 0.45],\n",
        "#  [0.29, 0.45, 0.29]]\n",
        "\n",
        "grid_print(board3.state, 2, 0, \"Board 3\")\n",
        "mcts_searcher3 = MCTS(board3)\n",
        "grid_print(mcts_searcher3.search(), 5, 2, \"Value grid\")\n",
        "# [[ 0.00, -0.10, -0.17],\n",
        "#  [-0.10,  0.00, -0.10],\n",
        "#  [-0.17, -0.10,  0.00]]\n"
      ],
      "metadata": {
        "id": "PoFIvTtrb3oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stage 2: Converting scores into probabilities\n",
        "\n",
        "All these negative and positives scores are rather difficult to interpret, since we have to remember which player's turn it is to move. Let's convert them into probabilities instead, where the highest probabilities are assigned to the **best moves for the player whose turn it is**."
      ],
      "metadata": {
        "id": "z7GinTE4Gv2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise\n",
        "import torch\n",
        "import random\n",
        "\n",
        "class MCTS:\n",
        "    def __init__(self, board):\n",
        "        self.board = board\n",
        "\n",
        "    def simulate(self, board, reps):\n",
        "        total_value = 0\n",
        "        for _ in range (reps):\n",
        "            total_value += self.play_random_game(board.deepcopy())\n",
        "        return total_value / reps\n",
        "\n",
        "    def play_random_game(self, board):\n",
        "        game_on = True\n",
        "        while game_on:\n",
        "            move = random.choice(board.empties)\n",
        "            board.make_move(move)\n",
        "            value = board.outcome(move)\n",
        "            if value != None:\n",
        "                return value\n",
        "\n",
        "    def search(self):\n",
        "        move_probability_grid = [[0.0 for x in range(3)] for y in range(3)]\n",
        "        for move in self.board.empties:\n",
        "            new_board = self.board.deepcopy()\n",
        "            new_board.make_move(move)\n",
        "            if new_board.outcome(move) != None:\n",
        "                value = new_board.outcome(move)\n",
        "            else:\n",
        "                value = self.simulate(new_board, 5000)\n",
        "            move_probability_grid[move[1]][move[0]] = value\n",
        "        return move_probability_grid\n",
        "\n",
        "\n",
        "# Test cases\n",
        "board1 = Board(3, 3, 3, 1)\n",
        "board1.make_move((0, 0))\n",
        "board1.make_move((1, 1))\n",
        "board1.make_move((0, 1))\n",
        "board1.make_move((0, 2))\n",
        "\n",
        "board2 = Board(3, 3, 3, 1)\n",
        "board2.make_move((0, 0))\n",
        "\n",
        "board3 = Board(3, 3, 3, 1)\n",
        "board3.make_move((0, 0))\n",
        "board3.make_move((1, 1))\n",
        "board3.make_move((2, 2))\n",
        "\n",
        "# Your final probabilities should roughly resemble the probabilities in the grids below\n",
        "grid_print(board1.state, 2, 0, \"Board 1\")\n",
        "mcts_searcher1 = MCTS(board1)\n",
        "grid_print(mcts_searcher1.search(), 5, 2, \"Value grid\")\n",
        "# [[0.00, 0.09, 0.87],\n",
        "#  [0.00, 0.00, 0.00],\n",
        "#  [0.00, 0.03, 0.01]]\n",
        "\n",
        "grid_print(board2.state, 2, 0, \"Board 2\")\n",
        "mcts_searcher2 = MCTS(board2)\n",
        "grid_print(mcts_searcher2.search(), 5, 2, \"Value grid\")\n",
        "# [[0.00, 0.05, 0.13],\n",
        "#  [0.05, 0.41, 0.05],\n",
        "#  [0.13, 0.05, 0.13]]\n",
        "\n",
        "grid_print(board3.state, 2, 0, \"Board 3\")\n",
        "mcts_searcher3 = MCTS(board3)\n",
        "grid_print(mcts_searcher3.search(), 5, 2, \"Value grid\")\n",
        "# [[0.00, 0.14, 0.22],\n",
        "#  [0.14, 0.00, 0.14],\n",
        "#  [0.22, 0.14, 0.00]]"
      ],
      "metadata": {
        "id": "9zamCPzYIFMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice work!\n",
        "\n",
        "Short summary of my solution:\n",
        "\n",
        "1. I used a function from pytorch (softmax) which converts raw values into probabilities. It assigns higher values higher probabilities.\n",
        "\n",
        "2. Since our MCTS function always assigns the most positive scores to the moves which it thinks will lead to the 1s player winning, whenever it was the -1s player's turn to move, I multiplied all the scores by -1, before applying the softmax function.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6RHZx8tMuokV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution\n",
        "import random\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MCTS:\n",
        "    def __init__(self, board):\n",
        "        self.board = board\n",
        "\n",
        "    def simulate(self, board, reps):\n",
        "        total_value = 0\n",
        "        for _ in range (reps):\n",
        "            total_value += self.play_random_game(board.deepcopy())\n",
        "        return total_value / reps\n",
        "\n",
        "    def play_random_game(self, board):\n",
        "        game_on = True\n",
        "        while game_on:\n",
        "            move = random.choice(board.empties)\n",
        "            board.make_move(move)\n",
        "            value = board.outcome(move)\n",
        "            if value != None:\n",
        "                return value\n",
        "\n",
        "    def search(self):\n",
        "        move_probs = []\n",
        "        moves = []\n",
        "\n",
        "        for move in self.board.empties:\n",
        "            new_board = self.board.deepcopy()\n",
        "            new_board.make_move(move)\n",
        "            if new_board.outcome(move) != None:\n",
        "                value = new_board.outcome(move)\n",
        "            else:\n",
        "                value = self.simulate(new_board, 5000)\n",
        "            moves.append(move)\n",
        "            move_probs.append(value)\n",
        "        if self.board.turn == -1.0:\n",
        "            move_probs = [-1.0 * x for x in move_probs]\n",
        "\n",
        "        move_probs = F.softmax(torch.tensor(move_probs) * 7, dim=0)  # Convert legal moves to probabilities. Higher values get a higher probability. Multiplier of 7 is used to emphasize the difference between good moves and bad moves, otherwise the probabilities returned by softmax will all be too similar.\n",
        "        move_probability_grid = [[0.0 for x in range(3)] for y in range(3)]\n",
        "        for i, move in enumerate(moves):  # Fill in the move probability grid with the probabilities of legal moves, while leaving the occupied squares(aka illegal moves) with a probability of 0.0\n",
        "            move_probability_grid[move[1]][move[0]] = move_probs[i]\n",
        "        return move_probability_grid\n",
        "\n",
        "# Test cases\n",
        "board1 = Board(3, 3, 3, 1)\n",
        "board1.make_move((0, 0))\n",
        "board1.make_move((1, 1))\n",
        "board1.make_move((0, 1))\n",
        "board1.make_move((0, 2))\n",
        "\n",
        "board2 = Board(3, 3, 3, 1)\n",
        "board2.make_move((0, 0))\n",
        "\n",
        "board3 = Board(3, 3, 3, 1)\n",
        "board3.make_move((0, 0))\n",
        "board3.make_move((1, 1))\n",
        "board3.make_move((2, 2))\n",
        "\n",
        "# Your final probabilities should roughly resemble the probabilities in the grids below\n",
        "grid_print(board1.state, 2, 0, \"Board 1\")\n",
        "mcts_searcher1 = MCTS(board1)\n",
        "grid_print(mcts_searcher1.search(), 5, 2, \"Value grid\")\n",
        "# [[0.00, 0.09, 0.87],\n",
        "#  [0.00, 0.00, 0.00],\n",
        "#  [0.00, 0.03, 0.01]]\n",
        "\n",
        "grid_print(board2.state, 2, 0, \"Board 2\")\n",
        "mcts_searcher2 = MCTS(board2)\n",
        "grid_print(mcts_searcher2.search(), 5, 2, \"Value grid\")\n",
        "# [[0.00, 0.05, 0.13],\n",
        "#  [0.05, 0.41, 0.05],\n",
        "#  [0.13, 0.05, 0.13]]\n",
        "\n",
        "grid_print(board3.state, 2, 0, \"Board 3\")\n",
        "mcts_searcher3 = MCTS(board3)\n",
        "grid_print(mcts_searcher3.search(), 5, 2, \"Value grid\")\n",
        "# [[0.00, 0.14, 0.22],\n",
        "#  [0.14, 0.00, 0.14],\n",
        "#  [0.22, 0.14, 0.00]]"
      ],
      "metadata": {
        "id": "nQhBrk3CaaGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After we run the cell, we can see our algorithm performs quite well in the first two examples.\n",
        "\n",
        "In the 1st example, it is able to recognize the obvious opponent win threat and suggest a move to block it.\n",
        "\n",
        "Furthermore, in the 2nd example it is even able to recognize that the best move is to play in the center (Any other move results in a loss with best play from both sides. You can verify this for yourself).\n",
        "\n",
        "However, in the 3rd position, the top two moves recommended by the algoritm are actually the only two losing moves! What??!\n",
        "\n",
        "Clearly a human would see if they placed a token in say, the top right corner at (2, 0) their opponent would naturally block them by placing on the bottom left corner at (0, 2) which gives them two win threats at the same time.\n",
        "```python\n",
        "[[1,  0, -1],\n",
        " [0, -1,  0],\n",
        " [1,  0,  1]]\n",
        "```\n",
        "\n",
        "This result doesn't change even with more simulations. Isn't MCTS supposed return the best move given enough time?\n",
        "\n",
        "Yes! But what we have is only part of MCTS. Right now, our algorithm, doesn't account for the fact that most games have some level of intelligent moves on both sides. Like if the opponent sees a chance to complete 3 in a row, they will. Not place a token randomly.\n",
        "\n",
        "Now how might we implement that?\n",
        "\n",
        "üõë + üß†\n",
        "\n",
        "If you like a good challenge, I encourage you to try creating your own move chooser function to replace the ```random.choice``` line in the ```play_random_game``` method of the MCTS class.\n",
        "```python\n",
        "def play_random_game(self, board):\n",
        "    game_on = True\n",
        "    while game_on:\n",
        "        move = random.choice(board.empties)  # replace this line\n",
        "        board.make_move(move)\n",
        "        value = board.outcome(move)\n",
        "        if value != None:\n",
        "            return value\n",
        "\n",
        "def choose_move(board):\n",
        "    pass\n",
        "```\n",
        "\n",
        "One idea for choosing moves might be to query the neural network for moves. At first with an untrained network, this is equivalent to playing random moves, but as we do training iterations the network will get better.\n",
        "\n",
        "Ooh... that might work! Let's go with that.\n",
        "\n",
        "So our best move algorithm will be a version of MCTS that evaluates moves with simulations of the neural network playing against itself.\n",
        "\n",
        "Instead of ```move = random.choice(board.empties)```\n",
        ", we'll use ```move = network(board.state)```\n",
        "which is basically asking the network what move it would play in a given board state. Since our network hasn't been set up yet, we'll continue using ```random.choice``` as a placeholder for the rest of the game generation section."
      ],
      "metadata": {
        "id": "dKD4gynnLTqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stage 3: Move selection\n",
        "\n",
        "Now that we have a solid MCTS algorithm which returns a move probability grid, what we want is for the **probability of any specific move being played to correspond with its value in the probability grid**. For example, if our MCTS algorithm assigns a probability of 0.90 to a move_1 and 0.10 to move_2 in a given position, then move_1 should be played 90% of the time and move_2 should be played 10% of the time when that position arises.\n",
        "\n",
        "I added a few extra lines to the MCTS search output to help get you started."
      ],
      "metadata": {
        "id": "xW3yVWnsaVgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise\n",
        "import random\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MCTS:\n",
        "    def __init__(self, board):\n",
        "        self.board = board\n",
        "\n",
        "    def simulate(self, board, reps):\n",
        "        total_value = 0\n",
        "        for _ in range (reps):\n",
        "            total_value += self.play_random_game(board.deepcopy())\n",
        "        return total_value / reps\n",
        "\n",
        "    def play_random_game(self, board):\n",
        "        game_on = True\n",
        "        while game_on:\n",
        "            move = random.choice(board.empties)\n",
        "            board.make_move(move)\n",
        "            value = board.outcome(move)\n",
        "            if value != None:\n",
        "                return value\n",
        "\n",
        "    def search(self):\n",
        "        move_probs = []\n",
        "        moves = []\n",
        "\n",
        "        for move in self.board.empties:\n",
        "            new_board = self.board.deepcopy()\n",
        "            new_board.make_move(move)\n",
        "            if new_board.outcome(move) != None:\n",
        "                value = new_board.outcome(move)\n",
        "            else:\n",
        "                value = self.simulate(new_board, 5000)\n",
        "            moves.append(move)\n",
        "            move_probs.append(value)\n",
        "        if self.board.turn == -1.0:\n",
        "            move_probs = [-1.0 * x for x in move_probs]\n",
        "        move_probs = F.softmax(torch.tensor(move_probs) * 7, dim=0)  # Convert legal moves to probabilities. Higher values get a higher probability. Multiplier of 7 is used to emphasize the difference between good moves and bad moves, otherwise the probabilities returned by softmax will all be too similar.\n",
        "        move_probability_grid = [[0.0 for x in range(3)] for y in range(3)]\n",
        "        for i, move in enumerate(moves):  # Fill in the move probability grid with the probabilities of legal moves, while leaving the occupied squares(aka illegal moves) with a probability of 0.0\n",
        "            move_probability_grid[move[1]][move[0]] = move_probs[i]\n",
        "        return move_probability_grid\n",
        "\n",
        "def select_move():\n",
        "    pass\n",
        "\n",
        "\n",
        "board1 = Board(3, 3, 3, 1)\n",
        "board1.make_move((0, 0))\n",
        "board1.make_move((1, 1))\n",
        "board1.make_move((0, 1))\n",
        "board1.make_move((0, 2))\n",
        "\n",
        "mcts_searcher1 = MCTS(board1)\n",
        "mcts_out = mcts_searcher1.search()\n",
        "value_grid = [\n",
        "[  0.00,   0.08,   0.88,],\n",
        "[  0.00,   0.00,   0.00,],\n",
        "[  0.00,   0.03,   0.01,]\n",
        "]\n",
        "grid_print(value_grid, 5, 2, \"Value grid\")\n",
        "\n",
        "# Play a move using the move selection function and record how many times each move was played\n",
        "move_counts = {}\n",
        "reps = 1000\n",
        "for i in range(reps):\n",
        "    move = (0, 0)  # Replace this line\n",
        "    if move in move_counts:\n",
        "        move_counts[move] += 1\n",
        "    else:\n",
        "        move_counts[move] = 1\n",
        "\n",
        "move_prob_grid = [[0.0 for x in range(3)] for y in range(3)]\n",
        "for move in move_counts.keys():\n",
        "    move_counts[move] /= reps\n",
        "    move_prob_grid[move[1]][move[0]] = move_counts[move]\n",
        "\n",
        "# The value grid should be nearly identical to the distribution of moves played\n",
        "grid_print(move_prob_grid, 5, 2, \"Distribution of moves played\")"
      ],
      "metadata": {
        "id": "BeNhM3rf7l_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And that's the final part of our move chooser!\n",
        "\n",
        "Short summary of my solution:\n",
        "1. I altered the MCTS search function to return the moves and move probabilities along with the move grid. The indexes for ```moves``` and ```move_probs``` are aligned, meaning ```moves[0]``` returns the first move and ```move_probs[0]``` returns the probability assigned to that first move.\n",
        "2. I used ```np.random.multinomial``` to selects a move from the ```move_probs``` list based on the probabilities.\n",
        "\n",
        "Here's an example to clarify what ```np.random.multinomial``` does:\n",
        "```python\n",
        "moves_list = [\"left\", \"right\", \"up\"]\n",
        "probabilities_list = [0.1, 0.2, 0.7]\n",
        "selected_idx = np.random.multinomial(1, probabilities_list)\n",
        "```\n",
        "\n",
        "The first parameter of 1 tells us we only want to take 1 sample from ```probabilities_list```.\n",
        "\n",
        "Then ```np.random.multinomial``` returns a list with the results of how many times each item in ```probabilities_list``` was chosen\n",
        "\n",
        "\n",
        "\n",
        "When we draw only one sample:\n",
        "\n",
        "10% of the time selected_idx will = ```[1, 0, 0]```\n",
        "\n",
        "20% of the time selected_idx will = ```[0, 1, 0]```\n",
        "\n",
        "70% of the time selected_idx will = ```[0, 0, 1]```\n",
        "\n",
        "Then ```np.where(selected_idx==1)[0][0]``` tells us the index of the item with value = 1. Finally we use that index to access the corresponding move in ```moves_list```.\n",
        "\n"
      ],
      "metadata": {
        "id": "TlROMFQMvUd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MCTS:\n",
        "    def __init__(self, board):\n",
        "        self.board = board\n",
        "\n",
        "    def simulate(self, board, reps):\n",
        "        total_value = 0\n",
        "        for _ in range (reps):\n",
        "            total_value += self.play_random_game(board.deepcopy())\n",
        "        return total_value / reps\n",
        "\n",
        "    def play_random_game(self, board):\n",
        "        game_on = True\n",
        "        while game_on:\n",
        "            move = random.choice(board.empties)\n",
        "            board.make_move(move)\n",
        "            value = board.outcome(move)\n",
        "            if value != None:\n",
        "                return value\n",
        "\n",
        "    def search(self):\n",
        "        move_probs = []\n",
        "        moves = []\n",
        "\n",
        "        for move in self.board.empties:\n",
        "            new_board = self.board.deepcopy()\n",
        "            new_board.make_move(move)\n",
        "            if new_board.outcome(move) != None:\n",
        "                value = new_board.outcome(move)\n",
        "            else:\n",
        "                value = self.simulate(new_board, 5000)\n",
        "            moves.append(move)\n",
        "            move_probs.append(value)\n",
        "        if self.board.turn == -1.0:\n",
        "            move_probs = [-1.0 * x for x in move_probs]\n",
        "        move_probs = F.softmax(torch.tensor(move_probs) * 7, dim=0)  # Convert legal moves to probabilities. Higher values get a higher probability. Multiplier of 7 is used to emphasize the difference between good moves and bad moves, otherwise the probabilities returned by softmax will all be too similar.\n",
        "        move_probs = move_probs.tolist()\n",
        "        move_probability_grid = [[0.0 for x in range(3)] for y in range(3)]\n",
        "        for i, move in enumerate(moves):  # Fill in the move probability grid with the probabilities of legal moves, while leaving the occupied squares(aka illegal moves) with a probability of 0.0\n",
        "            move_probability_grid[move[1]][move[0]] = move_probs[i]\n",
        "        return move_probability_grid, move_probs, moves\n",
        "\n",
        "def select_move(move_probs, moves):\n",
        "    selected_idx = np.random.multinomial(1, move_probs)\n",
        "    return moves[np.where(selected_idx==1)[0][0]]\n",
        "\n",
        "\n",
        "board1 = Board(3, 3, 3, 1)\n",
        "board1.make_move((0, 0))\n",
        "board1.make_move((1, 1))\n",
        "board1.make_move((0, 1))\n",
        "board1.make_move((0, 2))\n",
        "\n",
        "mcts_searcher1 = MCTS(board1)\n",
        "mcts_out = mcts_searcher1.search()\n",
        "grid_print(mcts_out[0], 5, 2, \"Value grid\")\n",
        "\n",
        "# Play a move using the move selection function and record how many times each move was played\n",
        "move_counts = {}\n",
        "reps = 1000\n",
        "for i in range(reps):\n",
        "    move = select_move(mcts_out[1], mcts_out[2])\n",
        "    if move in move_counts:\n",
        "        move_counts[move] += 1\n",
        "    else:\n",
        "        move_counts[move] = 1\n",
        "\n",
        "move_prob_grid = [[0.0 for x in range(3)] for y in range(3)]\n",
        "for move in move_counts.keys():\n",
        "    move_counts[move] /= reps\n",
        "    move_prob_grid[move[1]][move[0]] = move_counts[move]\n",
        "\n",
        "# The value grid should be nearly identical to the distribution of moves played\n",
        "grid_print(move_prob_grid, 5, 2, \"Distribution of moves played\")"
      ],
      "metadata": {
        "id": "zv2O55RAvUQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating the game dataset"
      ],
      "metadata": {
        "id": "ktczsh21HNmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it's time to put together everything we did earlier!\n",
        "\n",
        "What we want to do now, is create a function which simulates a bunch of games while adding the positions along with their best moves to a list."
      ],
      "metadata": {
        "id": "ihlqnxOfmGlK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A desired sample output would like something like this:\n",
        "\n",
        "```python\n",
        "[\n",
        "  # First position + best_moves pair\n",
        "  (\n",
        "    # position\n",
        "    [[0,  0,  0],\n",
        "     [0, -1,  0],\n",
        "     [0,  0,  0]],\n",
        "    # move probabilities\n",
        "    [[0.25, 0.00, 0.25],\n",
        "     [0.00, 0.00, 0.00],\n",
        "     [0.25, 0.00, 0.25]]\n",
        "  ),\n",
        "  # Second position + best_moves pair\n",
        "  (\n",
        "    # position\n",
        "    [[ 0,  0,  1],\n",
        "     [ 0, -1, -1],\n",
        "     [ 0,  0,  0]],\n",
        "    # move probabilities\n",
        "    [[0.00, 0.00, 0.00],\n",
        "     [1.00, 0.00, 0.00],\n",
        "     [0.00, 0.00, 0.00]]\n",
        "  )\n",
        "  # And so on...\n",
        "```\n",
        "Keep in mind the move probabilities grids we actually get from MCTS won't always recommend the best moves so accurately like in the examples above.\n",
        "\n",
        "I've pasted the latest board and mcts code below for convenience. The number of random playouts in MCTS has been greatly **reduced** so our game generation runs at a reasonable speed.\n",
        "\n",
        "Make sure to copy and paste that right underneath the Board class at top of your code editor or run the cell if using Google Colab. The rest of the game generation code is all you!"
      ],
      "metadata": {
        "id": "pDmH-pvJ7nUd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Final MCTS code"
      ],
      "metadata": {
        "id": "EoKw7XFAImLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class MCTS:\n",
        "    def __init__(self, board):\n",
        "        self.board = board\n",
        "\n",
        "    def simulate(self, board, reps):\n",
        "        total_value = 0\n",
        "        for _ in range (reps):\n",
        "            total_value += self.play_random_game(board.deepcopy())\n",
        "        return total_value / reps\n",
        "\n",
        "    def play_random_game(self, board):\n",
        "        game_on = True\n",
        "        while game_on:\n",
        "            move = random.choice(board.empties)\n",
        "            board.make_move(move)\n",
        "            value = board.outcome(move)\n",
        "            if value != None:\n",
        "                return value\n",
        "\n",
        "    def search(self):\n",
        "        move_probs = []\n",
        "        moves = []\n",
        "\n",
        "        for move in self.board.empties:\n",
        "            new_board = self.board.deepcopy()\n",
        "            new_board.make_move(move)\n",
        "            if new_board.outcome(move) != None:\n",
        "                value = new_board.outcome(move)\n",
        "            else:\n",
        "                value = self.simulate(new_board, 200)\n",
        "            moves.append(move)\n",
        "            move_probs.append(value)\n",
        "        if self.board.turn == -1.0:\n",
        "            move_probs = [-1.0 * x for x in move_probs]\n",
        "        move_probs = F.softmax(torch.tensor(move_probs) * 7, dim=0)  # Convert legal moves to probabilities. Higher values get a higher probability. Multiplier of 7 is used to emphasize the difference between good moves and bad moves, otherwise the probabilities returned by softmax will all be too similar.\n",
        "        move_probs = move_probs.tolist()\n",
        "        move_probability_grid = [[0.0 for x in range(3)] for y in range(3)]\n",
        "        for i, move in enumerate(moves):  # Fill in the move probability grid with the probabilities of legal moves, while leaving the occupied squares(aka illegal moves) with a probability of 0.0\n",
        "            move_probability_grid[move[1]][move[0]] = move_probs[i]\n",
        "        return move_probability_grid, move_probs, moves\n",
        "\n",
        "def select_move(move_probs, moves):\n",
        "    selected_idx = np.random.multinomial(1, move_probs)\n",
        "    return moves[np.where(selected_idx==1)[0][0]]"
      ],
      "metadata": {
        "id": "Rihehib0HaVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Game generation code"
      ],
      "metadata": {
        "id": "a-VPF3juIylL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise\n",
        "import pprint as pp\n",
        "\n",
        "def generate_games(num_games):\n",
        "    position_moveprob_pairs = []\n",
        "\n",
        "    # To have the pairs printed nicely, make sure to use torch.tensor to convert your board.state and move probability grid\n",
        "    # Example code shown below\n",
        "\n",
        "    # pair = (torch.tensor(board.state), torch.tensor(mcts_out[0]))\n",
        "    # position_moveprob_pairs.append(pair)\n",
        "\n",
        "    return position_moveprob_pairs\n",
        "\n",
        "position_moveprob_pairs = generate_games(1)\n",
        "pp.pp(position_moveprob_pairs)"
      ],
      "metadata": {
        "id": "dzmFgqRgOQdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Woohoo! We can now generate games for our network to train on!\n",
        "\n",
        "Short summary of my solution:\n",
        "1. I used the MCTS search to return a move probability grid of the current position before making a move\n",
        "2. I added the current position and move probability grid as a pair to our position + move probs database\n",
        "3. I used our ```select_move``` function to determine which move to play based on the move probabilities in our move probability grid."
      ],
      "metadata": {
        "id": "R6AWA0yAXNzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution\n",
        "import pprint as pp\n",
        "\n",
        "def generate_games(num_games):\n",
        "    position_moveprob_pairs = []\n",
        "    for _ in range(num_games):\n",
        "        board = Board(3, 3, 3, 1)\n",
        "        while True:\n",
        "            mcts_searcher = MCTS(board)\n",
        "            mcts_out = mcts_searcher.search()\n",
        "            position_moveprob_pairs.append((torch.tensor(board.state), torch.tensor(mcts_out[0])))\n",
        "\n",
        "            move = select_move(mcts_out[1], mcts_out[2])\n",
        "            board.make_move(move)\n",
        "            if board.outcome(move) != None:\n",
        "                break\n",
        "    return position_moveprob_pairs\n",
        "\n",
        "position_moveprob_pairs = generate_games(3)\n",
        "pp.pp(position_moveprob_pairs)"
      ],
      "metadata": {
        "id": "BDlUugBUSRQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now all we need is our neural network. We are almost there :D"
      ],
      "metadata": {
        "id": "xALVzAqXWq0v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o5sDMNUrx6s"
      },
      "source": [
        "### Building the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slYYlj060lLC"
      },
      "source": [
        "Now would be a great time to go and learn about the inner workings of a neural network if you haven't already, otherwise it'll be quite difficult to follow along. [Jump to neural network resources](#intro).\n",
        "\n",
        "Luckily, we don't have to build our network from scratch since developers before us built this handy library called pytorch. If you wanted to build your own neural networks from scratch, I'll link some resources at the end of the tutorial."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "JpYvuAGJy6n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we build a network in pytorch, all we need to do is specify what types of layers we'll be using in the ```__init__``` function and how they are connected in the ```forward``` function.\n",
        "\n",
        "Below is a example of a neural network that takes 1 input, has 2 neurons in its hidden layer, and has one output.\n",
        "\n",
        "Each layer can be thought of as an object that stores the values of the weights and biases between neurons. So the two red rectangles would represent the two layers in our neural network. Neurons can be thought of as the connection points or joints between layers in a neural network.\n"
      ],
      "metadata": {
        "id": "UphJ2TZly_6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "hoic01w2327y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell shows how we would use code to create the neural network above."
      ],
      "metadata": {
        "id": "KmlaMQWSZ06x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExampleNet(nn.Module): # inherit form pytorch's built in neural network class, nn.Module\n",
        "    def __init__(self):\n",
        "        # Defining the layers of our network\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(1, 2)  # nn.Linear creates a fully connected layer\n",
        "        self.fc2 = nn.Linear(2, 1)  # \"fc\" is a naming convention to indicate a fully connected layer\n",
        "\n",
        "    def forward(self, net_input):\n",
        "        # How are the layers connected to each other\n",
        "        x = self.fc1(net_input)\n",
        "        print(f\"Hidden layer neuron outputs: {x}\") #  Each item in the tensor corresponds to a hidden layer neuron's output\n",
        "        x = F.relu(x) # Applies relu activation function to each hidden layer neuron\n",
        "        print(f\"Hidden layer neuron outputs after relu: {x}\")\n",
        "        x = self.fc2(x)\n",
        "        print(f\"Final network output: {x}\")\n",
        "\n",
        "        return x\n",
        "\n",
        "net_in = torch.tensor([1.0])\n",
        "net = ExampleNet()\n",
        "net_out = net(net_in)\n"
      ],
      "metadata": {
        "id": "p9k-KcRks_eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course, these numbers and dimensions don't really mean much.\n",
        "\n",
        "Let's try building a network that takes in a 3x3 board and outputs a 3x3 move probability grid.\n",
        "\n",
        "Here are some things to note:\n",
        "- Fully connected layers only take 1 dimensional inputs, so assume our board will be flattened into a 1D input.\n",
        "- As for determining network size:\n",
        "  - The best approach is usually to go online and search for examples of models trained for similar purposes.\n",
        "  - Too small of a network means it will struggle to learn enough associations to play the game, and too large a network will result in longer training times and the network purely memorizing every position instead of generalizing.\n",
        "  - The rest of it is just trying out different network sizes until we find one that performs at our desired level.\n",
        "- Don't forget to apply the softmax function at the end to convert raw network values into a probability distribution\n"
      ],
      "metadata": {
        "id": "fBha5sKvvhh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TicTacToeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, net_input):\n",
        "        pass"
      ],
      "metadata": {
        "id": "cn99Yzwgyv66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's an example network. The key thing is that the number of input and output neurons should both be 9.\n",
        "\n",
        "We can experiment with the exact number of layers and neurons later."
      ],
      "metadata": {
        "id": "cGFWJjAsWixR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TicTacToeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(9, 32)\n",
        "        self.fc2 = nn.Linear(32, 9)\n",
        "\n",
        "    def forward(self, net_input):\n",
        "        x = self.fc1(net_input)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.softmax(x, dim=0)\n",
        "        return x"
      ],
      "metadata": {
        "id": "uo_Vv7W4bmG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, let's practice converting our board state into a 1D tensor. What's a tensor? Glad you asked!\n",
        "\n",
        "In programming terms, a tensor can be thought of as a datatype similar to a list that only takes numbers. However, in the context of neural networks, a tensor is a datatype which also keeps track of the gradients, which is how much each weight and bias contributed to the final loss in the output. This saves compute time and is also kinda necessary for certain parts of network training.\n",
        "\n",
        "The weights and biases in each layer of a neural network are stored as tensors, so in order for the computer to perform calculations between the weights + biases and the input, we must convert the input to a tensor first."
      ],
      "metadata": {
        "id": "kL0r0zJUgAzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = nn.Linear(4, 2)\n",
        "print(layer.weight)\n",
        "print(layer.bias)"
      ],
      "metadata": {
        "id": "ZD7SSEsjjDpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, tensors can come in any dimension. Each additional dimension is represented by another layer of nesting.\n",
        "\n",
        "```python\n",
        "# 0 dimensional Tensor aka scalar\n",
        "[0]\n",
        "# 1 dimensional Tensor aka vector\n",
        "[0, 1]\n",
        "# 2 dimensional Tensor aka matrix\n",
        "[[0, 1],\n",
        " [2, 3]]\n",
        "# 3 dimensional Tensor.\n",
        "[\n",
        "  [[0, 1],\n",
        "   [2, 3]],\n",
        "\n",
        "  [[4, 5],\n",
        "   [6, 7]]\n",
        "]\n",
        "```"
      ],
      "metadata": {
        "id": "mnlkUJBNrT5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enough about tensors. Let's see if you have the might to flatten a tensor!"
      ],
      "metadata": {
        "id": "wj1z8-xbrZUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "board = Board(3, 3, 3, 1)\n",
        "# I made some moves so it's easier to see where the numbers get mapped to on the flattened tensor.\n",
        "board.make_move((0, 0))\n",
        "board.make_move((1, 1))\n",
        "board.make_move((2, 2))\n",
        "\n",
        "# This is what the flattened board should look like\n",
        "flattened_board = torch.tensor([ 1.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  1.])\n",
        "\n",
        "net = TicTacToeNet()\n",
        "net_out = net(flattened_board)\n",
        "print(net_out)  # Actual network output is in the form of a 1D tensor\n",
        "print(net_out.view(board.width, board.height))  # View probabilites as a 3x3 grid"
      ],
      "metadata": {
        "id": "yKa8I7_OrdWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's how I did it.\n",
        "\n",
        "The .view() function reshapes the tensor to the specified size as long as the product of the dimensions remains the same. For example, a tensor with shape (6) can be reshaped to (2, 3) or (6, 1) or (6, 1, 1), and so on. In our case, we reshaped a tensor with shape (3, 3) to (9)\n"
      ],
      "metadata": {
        "id": "kxI3L3SjxZZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "board = Board(3, 3, 3, 1)\n",
        "#  I made some moves so it's easier to see where the numbers get mapped to on the flattened tensor.\n",
        "board.make_move((0, 0))\n",
        "board.make_move((1, 1))\n",
        "board.make_move((2, 2))\n",
        "\n",
        "board_as_tensor = torch.tensor(board.state)\n",
        "print(board_as_tensor)\n",
        "flattened_board = board_as_tensor.view(board.width * board.height)  # Flatten\n",
        "print(flattened_board)\n",
        "\n",
        "net = TicTacToeNet()\n",
        "net_out = net(flattened_board)\n",
        "print(net_out)  # Actual network output is in the form of a 1D tensor\n",
        "print(net_out.view(board.width, board.height))  # View probabilites as a 3x3 grid"
      ],
      "metadata": {
        "id": "LkL9vtfWxa_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These numbers in the grid are the probabilities the untrained network has assigned to each move. As you can see they're pretty random right now but it'll get better once the network starts trainingüèãÔ∏èüèãÔ∏èüèãÔ∏è.\n",
        "\n",
        "Whoa whoa whoa! I know you're excited to hit the gym to start training, but we still have some unfinished business.\n",
        "\n",
        "The last thing we need to do is write a function to replace ```random.choice``` with a network query in the random playouts section of our MCTS search.\n",
        "```python\n",
        "def play_random_game(self, board):  # not so random anymore!\n",
        "    game_on = True\n",
        "    while game_on:\n",
        "        move = random.choice(board.empties)  # replace this line\n",
        "        board.make_move(move)\n",
        "        value = board.outcome(move)\n",
        "        if value != None:\n",
        "            return value\n",
        "```\n",
        "Since the network will return probabilities for each move, we'd like the network to play each move with the same probability as shown in the probability grid.\n",
        "\n",
        "Before we move, we want to set all the illegal moves to a probability of 0 and recalculate the other probabilities so they add up to 1.0. For example, if we have probabilities of ```[0.25, 0.25, 0.50]``` but the last move is illegal, then our new probability distribution should look like ```[0.50, 0.50, 0.00]```\n",
        "\n",
        "If your code works, the network_move function should only suggest moves starting with (2, ...).\n",
        "\n",
        "We have already used all the functions/techniques you'll need to know to make this function. Good luck."
      ],
      "metadata": {
        "id": "YzLcdpsjpSxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def network_move(board, net):\n",
        "    pass\n",
        "\n",
        "board = Board(3, 3, 3, 1)\n",
        "board.make_move((0, 0))\n",
        "board.make_move((0, 1))\n",
        "board.make_move((0, 2))\n",
        "board.make_move((1, 0))\n",
        "board.make_move((1, 1))\n",
        "board.make_move((1, 2))\n",
        "net = TicTacToeNet()\n",
        "print(network_move(board, net))"
      ],
      "metadata": {
        "id": "WdJBOgVexDPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you haven't already figured it out, here are some hints:\n",
        "1. Convert the board into a format we can feed into the neural network\n",
        "2. Convert all probabilities for illegal moves to 0, and recalculate the rest of the probabilities\n",
        "3. Feed this new probability distribution to ```np.random.multinomial``` to select a move\n",
        "\n",
        "Here's my code which implements the 3 steps above."
      ],
      "metadata": {
        "id": "sdR8YCMixPCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def network_move(board, net):\n",
        "    board_as_tensor = torch.tensor(board.state)\n",
        "    flattened_board = board_as_tensor.flatten()\n",
        "    net_out = net(flattened_board)\n",
        "    move_probs = net_out.tolist()\n",
        "    moves = [(0, 0), (1, 0), (2, 0), (0, 1), (1, 1), (1, 2), (0, 2), (1, 2), (2, 2)]  # The indices of the probabilities in the move_probs list correspond to the indices in the moves list\n",
        "    for move_index, move_prob in enumerate(move_probs):\n",
        "        move = moves[move_index]\n",
        "        if move not in board.empties:\n",
        "            move_probs[move_index] = 0\n",
        "    move_probs = np.array(move_probs)\n",
        "    move_probs /= np.sum(move_probs)\n",
        "    selected_idx = np.random.multinomial(1, move_probs)\n",
        "    chosen_move = moves[np.where(selected_idx==1)[0][0]]\n",
        "    return chosen_move\n",
        "\n",
        "board = Board(3, 3, 3, 1)\n",
        "board.make_move((0, 0))\n",
        "board.make_move((0, 1))\n",
        "board.make_move((0, 2))\n",
        "board.make_move((1, 0))\n",
        "board.make_move((1, 1))\n",
        "board.make_move((1, 2))\n",
        "net = TicTacToeNet()\n",
        "print(network_move(board, net))"
      ],
      "metadata": {
        "id": "hN8gbhPLrpa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And it works! Except the network just recommends random legal moves.\n",
        "\n",
        "You know what that means...\n",
        "\n",
        "Are you READY to begin training the network?!!"
      ],
      "metadata": {
        "id": "GsS7PYKdyg85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the network"
      ],
      "metadata": {
        "id": "Z0QOJ-6szZXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A quick recap of what we've done so far:\n",
        "1. We've created a function to generate position & best move data\n",
        "2. We've initialized an untrained network\n",
        "\n",
        "This leads us to our third and final step: Building the training pipeline.\n",
        "\n",
        "Our training pipeline involves the constant repetition of two steps until the network reaches our desired strength:\n",
        "1. Generate position & best move data through self-play\n",
        "2. Use this data to train the neural network\n",
        "\n",
        "We already have game generation, so all we need now is the training loop."
      ],
      "metadata": {
        "id": "zq_mb4s64fWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now's the time to recall what we need to train a neural network.\n",
        "\n",
        "üõë + üß†\n",
        "\n",
        "Done?\n",
        "\n",
        "1. We need a loss function, or a way to determine how far off our network's prediction is from the expected best move.\n",
        "2. We need to implement some form of gradient descent, which tells the network how it should adjust its weights and biases to minimize the loss\n",
        "\n",
        "By the way, don't worry about implementing these things from scratch. Pytorch does a lot of the heavylifting for us :)\n",
        "\n",
        "When training our neural network, we'll be penalizing the network based on how far off its suggested moves are from our MCTS move probability grid. What's a good way to do that?\n",
        "\n",
        "Remember that a greater loss function means the network was less accurate.\n",
        "\n",
        "üõë + üß†\n",
        "\n",
        "One simple method you may have encountered before is to simply take the square of the difference between each probability in the two grids. For example, if the network assigns a probability of 0.60 to the move (0, 0), but the MCTS search assigns it a probability of 0.10, then our loss for that move is (0.6 - 0.1)^2 = 0.5^2 = 0.25. We then repeat this for each move and take the average of the losses.\n",
        "\n",
        "We could even code this manually except it'd be inconvenient to fit it in with the rest of the automation Pytorch does for us (namely the gradient descent), so let's just find the equivalent built-in pytorch function.\n",
        "\n",
        "It's called MSE (Mean squared error) loss. Here's how to use it:\n",
        "\n",
        "1. We create an object called ```loss_metric``` that calculates loss between a prediction and target with ```nn.MSELoss()```\n",
        "2. We pass in the target and prediction, and it'll tell us the loss.\n"
      ],
      "metadata": {
        "id": "nyZveCrjv4AX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.set_grad_enabled(True)\n",
        "\n",
        "loss_metric = nn.MSELoss()\n",
        "prediction = torch.tensor([0.6, 0.8])\n",
        "target = torch.tensor([0.1, 0.8])\n",
        "# Loss for (0.6 - 0.1)^2 = 0.25\n",
        "# Loss for (0.8 - 0.8)^2 = 0\n",
        "# Average of the two losses = 0.125\n",
        "loss = loss_metric(prediction, target)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "e5JmH2hd5lia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's next?\n",
        "\n",
        "The gradient descent part, or adjusting the network's weights and biases after each training example or batch of training examples. Now this would be a little time consuming to code, but luckily, Pytorch has all of that neatly packaged into one function, also known as our optimizer.\n",
        "\n",
        "The optimizer can be thought of as an object that has gradient descent as one of the methods/functions it can call. We'll be using minibatch stochastic gradient descent, which is essentially when we show the network a group/batch of position + move probability pairings, and adjust the weights and biases based on just the group. Why?\n",
        "\n",
        "The main reason is it's experimentally proven to be faster than using all the training data in every single gradient descent step.\n",
        "\n",
        "The specific optimizer that we'll be using is called the Adam optimizer, and the simple way to think of it is just an object with a method/function that performs gradient descent using batches of the training data.\n",
        "\n",
        "In reality the adam optimization algorithm does extra things like adaptive learning rates and momentum, but for our purposes it's just our gradient descent function.\n",
        "\n",
        "Here's how we create an instance of the Adam optimizer. We feed it the network's parameters along with our desired learning rate. A larger learning rate means the network will make larger adjustments during each iteration of the training loop."
      ],
      "metadata": {
        "id": "AJmwPOs-5Pa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# net = TicTacToeNet()\n",
        "# optimizer = torch.optim.Adam(net.parameters(), lr=0.003)"
      ],
      "metadata": {
        "id": "_ccjeHP3egjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To perform one step of gradient descent, what do we do? Think general steps, no need to come up with code.\n",
        "\n",
        "üõë + üß†\n",
        "\n",
        "Here's the main steps\n",
        "\n",
        "1. We compute the loss between the network's prediction and our target output.\n",
        "2. We call the ```loss.backward()``` function, which calculates the gradients for each of the network's parameters in relation to the loss. In other words, how much is each weight and bias affecting the overall loss calculation, and which way do we need to adjust it to reduce the loss?\n",
        "3. We call the ```optimizer.step()``` function, which adjusts each of the weights and biases based on the gradients calculated with ```loss.backward()```.\n",
        "\n",
        "As a reminder, all weights and biases are stored in the form of Pytorch tensors (an object), which have a gradient variable/property. When the ```loss.backward()``` function is called, this gradient variable/property is set to the derivative of that weight or bias with respect to the loss function.\n",
        "\n",
        "Ok example time!"
      ],
      "metadata": {
        "id": "yDVJH090kF86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we set up a neural network with a single neuron and manually set the weight and bias. This way it's easier to do the calculations yourself if you want to try following along.\n",
        "\n",
        "In a single neuron network, the neural network is completely modeled by the equation y = Wx + b.\n",
        "\n",
        "```python\n",
        "# y = network output\n",
        "# W = weight\n",
        "# x = input\n",
        "# b = bias\n",
        "```\n",
        "\n",
        "For the purposes of our example, all we want is our network to give an output of 2 whenever it receives an input of 2.\n",
        "\n",
        "If you were to visualize this, all we want is the equation of the line for our single neuron network to pass through the point (2, 2)"
      ],
      "metadata": {
        "id": "RH72pkXrsFjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExampleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(1, 1)\n",
        "        self.fc1.weight.data = torch.tensor([[0.5]])\n",
        "        self.fc1.bias.data = torch.tensor([0.5])\n",
        "\n",
        "    def forward(self, net_input):\n",
        "        x = self.fc1(net_input)\n",
        "        return x"
      ],
      "metadata": {
        "id": "3AByOsPho8yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we create the network, loss metric, and optimizer objects, as well as a tensor storing the target output for our network."
      ],
      "metadata": {
        "id": "UQMj1bvftKee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the network, loss metric, and optimizer objects.\n",
        "net = ExampleNet()\n",
        "loss_metric = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)\n",
        "target = torch.tensor([2.0])"
      ],
      "metadata": {
        "id": "lJAMDGWctJRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We run an initial test on the network."
      ],
      "metadata": {
        "id": "TBsrikdwth5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = net(torch.tensor([2.0]))\n",
        "print(\"Net prediction\")\n",
        "print(prediction)\n",
        "print()\n",
        "loss = loss_metric(prediction, target)\n",
        "print(\"Loss\")\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "Rk-Dx87atUeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is where Pytorch's built-in functions start doing a lot of work for us. When we call loss.backward(), it uses backpropagation to determine how much each weight and bias affected the neural network's final output, and sets their gradients.\n",
        "\n"
      ],
      "metadata": {
        "id": "Xd0NCk1zt6Y1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "print(\"Weight & bias gradients set after loss.backward():\")\n",
        "print()\n",
        "print(\"Weight gradient\")\n",
        "print(net.fc1.weight.grad)\n",
        "print()\n",
        "print(\"Bias gradient\")\n",
        "print(net.fc1.bias.grad)\n",
        "print()"
      ],
      "metadata": {
        "id": "C4umlfR2sEv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we run the step() method of our Adam optimizer which uses the gradients of the weights and biases computed by loss.backward() to update them, making the model a little more accurate."
      ],
      "metadata": {
        "id": "Gky9pYoeW-Dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.step()\n",
        "print(\"\\nWeights & biases adjusted after optimizer.step():\")\n",
        "print(\"==== Weight ====\")\n",
        "print(net.fc1.weight.data)\n",
        "print()\n",
        "print(\"==== Bias ====\")\n",
        "print(net.fc1.bias.data)\n",
        "print()\n",
        "\n",
        "prediction = net(torch.tensor([2.0]))\n",
        "print(\"==== Net prediction ====\")\n",
        "print(prediction)\n",
        "print()\n",
        "print(\"==== Loss ====\")\n",
        "loss = loss_metric(prediction, target)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "mwDMGm_GXAPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we repeat this process with each new example in our training data, the network's weights and biases slowly get adjusted to make it more sensitive to specific patterns.\n",
        "\n",
        "Okay, time for an exercise!\n",
        "\n",
        "Create a training loop which applies the techniques we've learned to teach our network to model the equation of a line.\n",
        "\n",
        "Run the code below to create the training data. Each dictionary key represents the x coordinate and its item is the corresponding y coordinate of the point."
      ],
      "metadata": {
        "id": "YKCSd2l_mqTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make custom training set\n",
        "import random\n",
        "\n",
        "train_set = {}\n",
        "\n",
        "for _ in range(2000):\n",
        "    x = round(random.uniform(-10, 10), 4)\n",
        "    train_set[x] = round(3*x - 5, 6)"
      ],
      "metadata": {
        "id": "mdJWNxPlkm8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure to run ```optimizer.zero_grad()``` before ```loss.backward()``` to clear the gradients from the previous training loop iteration. Otherwise the gradients from ```loss.backward()``` will accumulate until the newtork start making adjustments that are too big (because of the large accumulated gradient)."
      ],
      "metadata": {
        "id": "GKSPmR33jAjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise\n",
        "net = ExampleNet()\n",
        "net_inputs = list(train_set.keys())\n",
        "\n",
        "loss_metric = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.0005)  # Suggested optimization function and learning rate\n",
        "\n",
        "epochs = 1\n",
        "for epoch in range(epochs):\n",
        "    # Adjust the neural network after calculating loss for each example\n",
        "\n",
        "    optimizer.zero_grad()  # Resets the gradients calculated for the weights and biases from the previous iteration of the training loop. Without this loss.backward just adds the new gradient value to the existing one.\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "EJUbIyCRiEn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congrats! You just created your first full training loop!\n",
        "\n",
        "Short summary of my solution:\n",
        "1. In each epoch, I used the epoch number to get a different input (key) from the dictionary and its corresponding output\n",
        "2. Then I used the loss function to compare the output value in the dictionary to the network's output when fed the same input\n",
        "3. Finally we call ```loss.backward()``` and ```optimizer.step()``` to adjust the network's weights and biases\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QwPMmzd6kGl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution\n",
        "net = ExampleNet()\n",
        "net_inputs = list(train_set.keys())\n",
        "epochs = len(net_inputs)\n",
        "\n",
        "\n",
        "loss_metric = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.0005)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    net_input = net_inputs[epoch]\n",
        "    target = torch.tensor([train_set[net_input]])\n",
        "    prediction = net(torch.tensor([net_input]))\n",
        "    loss = loss_metric(prediction, target)\n",
        "    optimizer.zero_grad()  # Resets the gradients calculated for the weights and biases from the previous iteration of the training loop. Without this loss.backward just adds the new gradient value to the existing one.\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch < 100 or epoch % 25 == 0:\n",
        "        print(f\"Epoch {epoch}\")\n",
        "        print(f\"Net input: {net_input}\")\n",
        "        print(f\"Weight: {net.fc1.weight.data}\")\n",
        "        print(f\"Weight gradient: {net.fc1.weight.grad}\")\n",
        "        print(f\"Bias: {net.fc1.bias.data}\")\n",
        "        print(f\"Bias gradient: {net.fc1.bias.grad}\")\n",
        "        print(f\"Target output: {target}\")\n",
        "        print(f\"Net output: {prediction}\")\n",
        "        print(f\"Loss: {loss}\")\n",
        "        print()\n",
        "    # To get the weight and bias for an epoch, subtract the (gradient * learning rate) from the weight or bias in the previous epoch\n",
        "    # W' = W - dW * a\n",
        "    # b' = b - db * a\n"
      ],
      "metadata": {
        "id": "DXm0oH4OoqMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Putting it all together"
      ],
      "metadata": {
        "id": "nJOYVb_qlaxq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have everything we need to create the tic-tac-toe network now!\n",
        "\n",
        "Make sure paste the code in the **cell below** to the top of your code editor.\n",
        "\n",
        "It contains all the classes and functions we built earlier including:\n",
        "1. Board class\n",
        "2. MCTS class\n",
        "3. Game generation function\n",
        "4. Network\n",
        "\n",
        "The MCTS class has been updated to use a neural network for its game simulations. When creating an MCTS object make sure to pass in the network as the second parameter.\n",
        "\n",
        "All that remains for us to do is implement the training loop and see our results! Good luck!!"
      ],
      "metadata": {
        "id": "pP4HrUP2mJ_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Previous classes & functions"
      ],
      "metadata": {
        "id": "W-WCidoIsHZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.set_grad_enabled(True)\n",
        "torch.set_printoptions(sci_mode=False, linewidth=120)"
      ],
      "metadata": {
        "id": "kVTDcJpQvApF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Board\"\"\"\n",
        "class Board:\n",
        "    def __init__(self, width, height, win_length, turn, state=None, empties=None):\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.win_length = win_length\n",
        "        self.turn = float(turn)\n",
        "        if state == None:\n",
        "            self.state = tuple([0.0 for _ in range (width)] for _ in range(height))\n",
        "            self.empties = [(x, y) for y in range (height) for x in range(width)]\n",
        "        else:\n",
        "            self.state = tuple([x for x in y] for y in state)\n",
        "            self.empties = [e for e in empties]\n",
        "    def __str__(self):\n",
        "        board_state_as_str = \"\"\n",
        "        board_state = [row.copy() for row in self.state]\n",
        "        for row in board_state:\n",
        "            for i, token in enumerate(row):\n",
        "                if token == 1.0:\n",
        "                    row[i] = \"X\"\n",
        "                elif token == -1.0:\n",
        "                    row[i] = \"O\"\n",
        "                elif token == 0.0:\n",
        "                    row[i] = \"_\"\n",
        "            board_state_as_str += str(row) + \"\\n\"\n",
        "        return board_state_as_str\n",
        "    def deepcopy(self):\n",
        "        board = Board(self.width, self.height, self.win_length, self.turn, self.state, self.empties)\n",
        "        return board\n",
        "    def out_of_bounds(self, square, max_x, max_y):\n",
        "        return (square[0] < 0 or square[1] < 0 or square[0] >= max_x or square[1] >= max_y)\n",
        "    def outcome(self, updated_square):\n",
        "        player_num = self.state[updated_square[1]][updated_square[0]]\n",
        "        vectors = []\n",
        "        for x in [-1, 0, 1]:\n",
        "            for y in [-1, 0, 1]:\n",
        "                if x == 0 and y == 0:\n",
        "                    continue\n",
        "                # if a neighbouring square is out of bounds, skip to the next coordinate\n",
        "                if updated_square[0] - 1 < 0 and x == -1:  # past left edge\n",
        "                    continue\n",
        "                if updated_square[0] + 1 > self.width - 1 and x == 1:  # past right edge\n",
        "                    continue\n",
        "                if updated_square[1] - 1 < 0 and y == -1:  # past top edge\n",
        "                    continue\n",
        "                if updated_square[1] + 1 > self.height - 1 and y == 1:  # past bottom edge\n",
        "                    continue\n",
        "                neighbour_x, neighbour_y = updated_square[0] + x, updated_square[1] + y\n",
        "                if self.state[neighbour_y][neighbour_x] == player_num:\n",
        "                    vector = (neighbour_x - updated_square[0], neighbour_y - updated_square[1])\n",
        "                    if vector not in [(v[0]*-1, v[1]*-1) for v in vectors]: # if there is not already a vector in the opposite direction\n",
        "                        vectors.append(vector)\n",
        "        for vector in vectors:\n",
        "            line_length = 1\n",
        "            reversing = False\n",
        "            i = 1\n",
        "            # Keep checking adjacent squares in one direction and increase the row length by 1 whenever the token matches the token just placed\n",
        "            # When an edge, empty space, or opponent token is encountered, count squares in the opposite direction skipping over all the ones we already counted\n",
        "            while i < self.win_length:\n",
        "                if not reversing:\n",
        "                    x = updated_square[0] + i * vector[0]\n",
        "                    y = updated_square[1] + i * vector[1]\n",
        "                    next_square = x, y\n",
        "                else:\n",
        "                    x = updated_square[0] + i * -vector[0]\n",
        "                    y = updated_square[1] + i * -vector[1]\n",
        "                    next_square = x, y\n",
        "\n",
        "                if self.out_of_bounds(next_square, self.width, self.height) \\\n",
        "                or self.state[next_square[1]][next_square[0]] != player_num:\n",
        "                    if not reversing:\n",
        "                        reversing = True\n",
        "                        i = 0\n",
        "                    else:\n",
        "                        break\n",
        "                else:\n",
        "                    line_length += 1\n",
        "                    if line_length >= self.win_length:\n",
        "                        return player_num\n",
        "                i += 1\n",
        "        if len(self.empties) == 0:\n",
        "            return 0.0\n",
        "        return None\n",
        "    def make_move(self, move_coords: tuple):\n",
        "        self.empties.remove(move_coords)\n",
        "        self.state[move_coords[1]][move_coords[0]] = self.turn\n",
        "        self.turn *= -1.0"
      ],
      "metadata": {
        "id": "qAhOcRBksJeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"MCTS\"\"\"\n",
        "def network_move(board, net):\n",
        "    board_as_tensor = torch.tensor(board.state)\n",
        "    flattened_board = board_as_tensor.view(board.width * board.height)\n",
        "    net_out = net(flattened_board)\n",
        "    move_probs = net_out.tolist()\n",
        "    moves = [(0, 0), (1, 0), (2, 0), (0, 1), (1, 1), (1, 2), (0, 2), (1, 2), (2, 2)]  # The indices of the probabilities in the move_probs list correspond to the indices in the moves list\n",
        "    for move_index, move_prob in enumerate(move_probs):\n",
        "        move = moves[move_index]\n",
        "        if move not in board.empties:\n",
        "            move_probs[move_index] = 0\n",
        "    move_probs = np.array(move_probs)\n",
        "    move_probs /= np.sum(move_probs)\n",
        "    selected_idx = np.random.multinomial(1, move_probs)\n",
        "    chosen_move = moves[np.where(selected_idx==1)[0][0]]\n",
        "    return chosen_move\n",
        "\n",
        "class MCTS:\n",
        "    def __init__(self, board, net):\n",
        "        self.board = board\n",
        "        self.net = net\n",
        "\n",
        "    def simulate(self, board, reps):\n",
        "        total_value = 0\n",
        "        for _ in range (reps):\n",
        "            total_value += self.play_random_game(board.deepcopy())\n",
        "        return total_value / reps\n",
        "\n",
        "    def play_random_game(self, board):\n",
        "        game_on = True\n",
        "        while game_on:\n",
        "            move = random.choice(board.empties)\n",
        "            board.make_move(move)\n",
        "            value = board.outcome(move)\n",
        "            if value != None:\n",
        "                return value\n",
        "\n",
        "    def search(self):\n",
        "        move_probs = []\n",
        "        moves = []\n",
        "\n",
        "        for move in self.board.empties:\n",
        "            new_board = self.board.deepcopy()\n",
        "            new_board.make_move(move)\n",
        "            if new_board.outcome(move) != None:\n",
        "                value = new_board.outcome(move)\n",
        "            else:\n",
        "                value = self.simulate(new_board, 200)\n",
        "            moves.append(move)\n",
        "            move_probs.append(value)\n",
        "        if self.board.turn == -1.0:\n",
        "            move_probs = [-1.0 * x for x in move_probs]\n",
        "        move_probs = F.softmax(torch.tensor(move_probs) * 7, dim=0)  # Convert legal moves to probabilities. Higher values get a higher probability. Multiplier of 7 is used to emphasize the difference between good moves and bad moves, otherwise the probabilities returned by softmax will all be too similar.\n",
        "        move_probs = move_probs.tolist()\n",
        "        move_probability_grid = [[0.0 for x in range(3)] for y in range(3)]\n",
        "        for i, move in enumerate(moves):  # Fill in the move probability grid with the probabilities of legal moves, while leaving the occupied squares(aka illegal moves) with a probability of 0.0\n",
        "            move_probability_grid[move[1]][move[0]] = move_probs[i]\n",
        "        return move_probability_grid, move_probs, moves"
      ],
      "metadata": {
        "id": "aTS5kh0LsKpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Game generation\"\"\"\n",
        "def select_move(move_probs, moves):\n",
        "    selected_idx = np.random.multinomial(1, move_probs)\n",
        "    return moves[np.where(selected_idx==1)[0][0]]\n",
        "\n",
        "def generate_games(num_games, net):\n",
        "    position_moveprob_pairs = []\n",
        "    for _ in range(num_games):\n",
        "        board = Board(3, 3, 3, 1)\n",
        "        while True:\n",
        "            mcts_searcher = MCTS(board, net)\n",
        "            mcts_out = mcts_searcher.search()\n",
        "            position_moveprob_pairs.append((torch.tensor(board.state) * board.turn, torch.tensor(mcts_out[0])))\n",
        "\n",
        "            move = select_move(mcts_out[1], mcts_out[2])\n",
        "            board.make_move(move)\n",
        "            if board.outcome(move) != None:\n",
        "                break\n",
        "    return position_moveprob_pairs"
      ],
      "metadata": {
        "id": "QLzDWCoVsR6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Network\"\"\"\n",
        "class TicTacToeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(9, 36)\n",
        "        self.fc2 = nn.Linear(36, 64)\n",
        "        self.fc3 = nn.Linear(64, 9)\n",
        "\n",
        "    def forward(self, net_input):\n",
        "        x = self.fc1(net_input)\n",
        "        x = F.selu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.selu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = F.softmax(x, dim=0)\n",
        "        return x"
      ],
      "metadata": {
        "id": "5UFgQGuZuwEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Starter training loop code"
      ],
      "metadata": {
        "id": "N7mgPvQJx04g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = TicTacToeNet()"
      ],
      "metadata": {
        "id": "hSpshoVFy55k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "games = generate_games(500, net)"
      ],
      "metadata": {
        "id": "nro5TJF4yx32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class TicTacToeDataset(Dataset):\n",
        "    def __init__(self, games):\n",
        "        super().__init__()\n",
        "        self.games = games\n",
        "    def __len__(self):\n",
        "        return len(self.games)\n",
        "    def __getitem__(self, index):\n",
        "        return self.games[index][0], self.games[index][1]\n",
        "\n",
        "train_data = TicTacToeDataset(games)\n",
        "train_data_loader = DataLoader(train_data, batch_size=1, shuffle=True, drop_last=False)"
      ],
      "metadata": {
        "id": "4qc9RishEQ-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It runs wayyyy too slowly üíÄ I did NOT test this... Well now we know. Ok let's try starting with random games, then shifting to network played games later."
      ],
      "metadata": {
        "id": "ETtVdohi6X8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution\n",
        "loss_metric = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.0003)\n",
        "\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0\n",
        "    for position, target_move_probs in train_data_loader:\n",
        "        position = games[epoch][0].flatten()\n",
        "        target_move_probs = games[epoch][1].flatten()\n",
        "        net_move_probs = net(position)\n",
        "\n",
        "        loss = loss_metric(net_move_probs, target_move_probs)\n",
        "        optimizer.zero_grad()  # Resets the gradients calculated for the weights and biases from the previous iteration of the training loop. Without this loss.backward just adds the new gradient value to the existing one.\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Training loss: {running_loss/len(train_data_loader)}\")"
      ],
      "metadata": {
        "id": "HcfxX7zyFHHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def network_move(board, net):\n",
        "    board_as_tensor = torch.tensor(board.state)\n",
        "    flattened_board = board_as_tensor.view(board.width * board.height)\n",
        "    net_out = net(flattened_board)\n",
        "    print(net_out.view(3, 3))\n",
        "    move_probs = net_out.tolist()\n",
        "    moves = [(0, 0), (1, 0), (2, 0), (0, 1), (1, 1), (1, 2), (0, 2), (1, 2), (2, 2)]  # The indices of the probabilities in the move_probs list correspond to the indices in the moves list\n",
        "    for move_index, move_prob in enumerate(move_probs):\n",
        "        move = moves[move_index]\n",
        "        if move not in board.empties:\n",
        "            print(move)\n",
        "            move_probs[move_index] = 0\n",
        "    move_probs = np.array(move_probs)\n",
        "    print(move_probs)\n",
        "    move_probs /= np.sum(move_probs)\n",
        "    print(move_probs)\n",
        "    selected_idx = np.random.multinomial(1, move_probs)\n",
        "    print(selected_idx)\n",
        "    chosen_move = moves[np.where(selected_idx==1)[0][0]]\n",
        "    return chosen_move\n",
        "\n",
        "def mcts_net_vs_human(board, mcts_reps, net):\n",
        "    game_on = True\n",
        "    while game_on:\n",
        "        if board.turn == 1:\n",
        "            print(f\"======= X player's turn to move =======\")\n",
        "            chosen_move = network_move(board, net)\n",
        "            board.make_move(chosen_move)\n",
        "        else:\n",
        "            print(f\"======= O player's turn to move =======\")\n",
        "            try:\n",
        "                x = input(\"x: \")\n",
        "                y = input(\"y: \")\n",
        "                chosen_move = (int(x), int(y))\n",
        "                board.make_move(chosen_move)\n",
        "            except Exception:\n",
        "                print(\"Invalid move, please try again\")\n",
        "                continue\n",
        "\n",
        "        print(\"Board:\")\n",
        "        print(board)\n",
        "        value = board.outcome(chosen_move)\n",
        "        if value != None:\n",
        "            break"
      ],
      "metadata": {
        "id": "fy6qHSNrLMPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcts_net_vs_human(Board(3, 3, 3, 1), 1, net)\n"
      ],
      "metadata": {
        "id": "-o2sYwLqP35l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWjjmMx3W8K-"
      },
      "source": [
        "### Other stuff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj8SVNNCC9Cf"
      },
      "source": [
        "Additional exercises:\n",
        "- Minimax as the evaluation function (start with a 3x3 board). What happens when we use a larger board? Can we use the neural network's value function as the heuristic for minimax?\n",
        "- Try adding in additonal inputs like win length, and 1 previous turn to see if it helps the network train faster!\n",
        "- Adjust parameters to see if you can get a better network\n",
        "- Creating additional training data with transformations\n",
        "- What if we tried using two channels for input, one for X and one for O?\n",
        "\n",
        "\n",
        "Once you complete the tutorial, feel free to run this in replit or VScode so you can set breakpoints to view the variables at various points in the code. I think it's very helpful for understanding!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79vQXlA-oPxy"
      },
      "source": [
        "Notes:\n",
        "- Beginning:\n",
        "  - As a bonus, I'll answer any questions you have within a few days, just submit them here: [link].\n",
        "  - Examples how ppl learned AI on their own and how far they got with it (internships), you can do it too!\n",
        "\n",
        "\n",
        "\n",
        "- Community\n",
        "- See what SoloLearn does well and lacks\n",
        "- Databricks\n",
        "- Images\n",
        "- Videos\n",
        "- Give examples of input for x and y coordinate"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}